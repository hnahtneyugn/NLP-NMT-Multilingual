{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc09bbc-5d7a-440e-91b4-0e56c60e3a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.10/site-packages (4.4.2)\n",
      "Requirement already satisfied: evaluate in ./.local/lib/python3.10/site-packages (0.4.6)\n",
      "Requirement already satisfied: sacrebleu in ./.local/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.10/site-packages (3.10.8)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: tensorboard in ./.local/lib/python3.10/site-packages (2.20.0)\n",
      "Requirement already satisfied: tiktoken in ./.local/lib/python3.10/site-packages (0.12.0)\n",
      "Requirement already satisfied: sentencepiece in ./.local/lib/python3.10/site-packages (0.2.1)\n",
      "Requirement already satisfied: pyvi in ./.local/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: laonlp in ./.local/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: transformers[torch] in ./.local/lib/python3.10/site-packages (4.57.3)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from torch) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.local/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.local/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.local/lib/python3.10/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.local/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.local/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.local/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.local/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.local/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.local/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.local/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.local/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.local/lib/python3.10/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.local/lib/python3.10/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.local/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.local/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.local/lib/python3.10/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.local/lib/python3.10/site-packages (from transformers[torch]) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from transformers[torch]) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.10/site-packages (from transformers[torch]) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.local/lib/python3.10/site-packages (from transformers[torch]) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.10/site-packages (from transformers[torch]) (0.7.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in ./.local/lib/python3.10/site-packages (from transformers[torch]) (1.12.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in ./.local/lib/python3.10/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in ./.local/lib/python3.10/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.10/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.10/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in ./.local/lib/python3.10/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: portalocker in ./.local/lib/python3.10/site-packages (from sacrebleu) (3.2.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in ./.local/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in ./.local/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in ./.local/lib/python3.10/site-packages (from sacrebleu) (6.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in ./.local/lib/python3.10/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.local/lib/python3.10/site-packages (from matplotlib) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: absl-py>=0.4 in ./.local/lib/python3.10/site-packages (from tensorboard) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in ./.local/lib/python3.10/site-packages (from tensorboard) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.local/lib/python3.10/site-packages (from tensorboard) (3.10)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in ./.local/lib/python3.10/site-packages (from tensorboard) (6.33.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.local/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.local/lib/python3.10/site-packages (from tensorboard) (3.1.4)\n",
      "Requirement already satisfied: scikit-learn in ./.local/lib/python3.10/site-packages (from pyvi) (1.7.2)\n",
      "Requirement already satisfied: sklearn-crfsuite in ./.local/lib/python3.10/site-packages (from pyvi) (0.5.0)\n",
      "Requirement already satisfied: pythainlp>=3.0.0 in ./.local/lib/python3.10/site-packages (from laonlp) (5.2.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]) (7.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.local/lib/python3.10/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.local/lib/python3.10/site-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.local/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.local/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.local/lib/python3.10/site-packages (from scikit-learn->pyvi) (3.6.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.7 in ./.local/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers[torch] datasets evaluate sacrebleu matplotlib tqdm tensorboard tiktoken sentencepiece pyvi laonlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f1c9e3-42a3-4a45-b6a5-8d9178295baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainerCallback,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "import sacrebleu\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0535e5c0-1675-41d0-92e1-430dba670bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. CONFIGURATION CLASS ---\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    model_name: str = \"google/mt5-base\"  # THIS WILL CHANGE IN EACH NOTEBOOK\n",
    "    output_dir: str = \"./t5_output\" # THIS WILL CHANGE IN EACH NOTEBOOK\n",
    "    \n",
    "    max_source_length: int = 128\n",
    "    max_target_length: int = 128\n",
    "    num_beams: int = 5\n",
    "    learning_rate: float = 5e-5\n",
    "    num_train_epochs: int = 4        # Set to 3 or 4 for your 700k dataset\n",
    "    per_device_train_batch_size: int = 128  # Increased for H200\n",
    "    per_device_eval_batch_size: int = 128\n",
    "    gradient_accumulation_steps: int = 2   # Reduced to 1 for speed\n",
    "    warmup_steps: int = 500\n",
    "    weight_decay: float = 0.01\n",
    "    logging_steps: int = 50\n",
    "    eval_strategy: str = \"steps\"\n",
    "    eval_steps: int = 1000           # Less frequent eval for speed\n",
    "    save_steps: int = 1000\n",
    "    save_total_limit: int = 2\n",
    "    early_stopping_patience: int = 3\n",
    "    fp16: bool = False\n",
    "    bf16: bool = True                # H200 supports BF16\n",
    "    dataloader_num_workers: int = 4\n",
    "    dataloader_pin_memory: bool = True\n",
    "    optim: str = \"adamw_torch_fused\"\n",
    "    predict_with_generate: bool = True\n",
    "    generation_max_length: int = 128\n",
    "    generation_num_beams: int = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f603eb7c-c9ac-475c-9f56-dcc76bf06368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. VISUALIZATION CALLBACK ---\n",
    "class ProgressVisualizationCallback(TrainerCallback):\n",
    "    def __init__(self, output_dir: str):\n",
    "        self.output_dir = output_dir\n",
    "        self.train_losses = []\n",
    "        self.eval_losses = []\n",
    "        self.eval_bleus = []\n",
    "        self.train_steps = []\n",
    "        self.eval_steps = []\n",
    "        self.plots_dir = os.path.join(output_dir, \"plots\")\n",
    "        os.makedirs(self.plots_dir, exist_ok=True)\n",
    "        \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            # Track Training Loss\n",
    "            if 'loss' in logs:\n",
    "                self.train_losses.append(logs['loss'])\n",
    "                self.train_steps.append(state.global_step)\n",
    "            \n",
    "            # Track Evaluation Loss & BLEU\n",
    "            # (These usually appear together in logs during eval steps)\n",
    "            if 'eval_loss' in logs:\n",
    "                self.eval_losses.append(logs['eval_loss'])\n",
    "                self.eval_steps.append(state.global_step)\n",
    "            if 'eval_bleu' in logs:\n",
    "                self.eval_bleus.append(logs['eval_bleu'])\n",
    "    \n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        # Create a figure with 3 side-by-side plots\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        # 1. Plot Training Loss\n",
    "        if self.train_losses:\n",
    "            axes[0].plot(self.train_steps, self.train_losses, label='Train Loss', color='blue')\n",
    "            axes[0].set_title('Training Loss')\n",
    "            axes[0].set_xlabel('Steps')\n",
    "            axes[0].set_ylabel('Loss')\n",
    "            axes[0].legend()\n",
    "            \n",
    "        # 2. Plot Validation Loss\n",
    "        if self.eval_losses:\n",
    "            axes[1].plot(self.eval_steps, self.eval_losses, label='Val Loss', color='orange')\n",
    "            axes[1].set_title('Validation Loss')\n",
    "            axes[1].set_xlabel('Steps')\n",
    "            axes[1].set_ylabel('Loss')\n",
    "            axes[1].legend()\n",
    "\n",
    "        # 3. Plot BLEU Score\n",
    "        if self.eval_bleus:\n",
    "            axes[2].plot(self.eval_steps, self.eval_bleus, label='BLEU', color='green')\n",
    "            axes[2].set_title('BLEU Score')\n",
    "            axes[2].set_xlabel('Steps')\n",
    "            axes[2].set_ylabel('Score')\n",
    "            axes[2].legend()\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save to file\n",
    "        plot_path = os.path.join(self.plots_dir, \"training_metrics.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        print(f\"Training finished. Plots saved to {plot_path}\")\n",
    "        \n",
    "        # Show in Notebook\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb9412d5-e994-41f9-b964-8bdde3416316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. DATA PREPARATOR (UPDATED WITH PYVI & LAONLP) ---\n",
    "from pyvi import ViTokenizer\n",
    "from laonlp.tokenize import word_tokenize\n",
    "\n",
    "class BilingualDatasetPreparator:\n",
    "    def __init__(self, tokenizer, config):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.config = config\n",
    "        \n",
    "    def create_dataset_from_files(self, vi_file: str, lo_file: str) -> Dataset:\n",
    "        with open(vi_file, 'r', encoding='utf-8') as f:\n",
    "            # Read ALL lines\n",
    "            vi_lines = f.readlines()\n",
    "        with open(lo_file, 'r', encoding='utf-8') as f:\n",
    "            lo_lines = f.readlines()\n",
    "            \n",
    "        # 1. Sanity Check\n",
    "        assert len(vi_lines) == len(lo_lines), f\"Raw file line counts mismatch! VI: {len(vi_lines)}, LO: {len(lo_lines)}\"\n",
    "\n",
    "        data = []\n",
    "        skipped_count = 0\n",
    "        \n",
    "        # 2. Iterate, Segment, and Filter\n",
    "        # We add tqdm here because segmentation takes more time than simple reading\n",
    "        print(f\"Segmenting and loading data from {vi_file} and {lo_file}...\")\n",
    "        for vi, lo in tqdm(zip(vi_lines, lo_lines), total=len(vi_lines), desc=\"Processing\"):\n",
    "            vi_clean = vi.strip()\n",
    "            lo_clean = lo.strip()\n",
    "            \n",
    "            # Only keep if BOTH have content\n",
    "            if vi_clean and lo_clean:\n",
    "                # --- NEW TOKENIZATION LOGIC START ---\n",
    "                \n",
    "                # Vietnamese: PyVi (Output: \"Học_sinh đi học\")\n",
    "                # PyVi adds underscores to compound words\n",
    "                vi_segmented = ViTokenizer.tokenize(vi_clean)\n",
    "                \n",
    "                # Lao: LaoNLP (Output: ['ພາສາ', 'ລາວ'])\n",
    "                # LaoNLP returns a list; we join with spaces for T5\n",
    "                lo_tokens = word_tokenize(lo_clean)\n",
    "                lo_segmented = \" \".join(lo_tokens)\n",
    "                \n",
    "                # --- NEW TOKENIZATION LOGIC END ---\n",
    "\n",
    "                data.append({\n",
    "                    'source': f\"translate Laos to Vietnamese: {lo_segmented}\", \n",
    "                    'target': vi_segmented\n",
    "                })\n",
    "            else:\n",
    "                skipped_count += 1\n",
    "        \n",
    "        print(f\"Loaded {len(data)} pairs. Skipped {skipped_count} empty/misaligned lines.\")\n",
    "        return Dataset.from_list(data)\n",
    "\n",
    "    def preprocess_function(self, examples):\n",
    "        # This function remains the same, but now it processes the ALREADY SEGMENTED text\n",
    "        # The T5 tokenizer will subword-tokenize the words/underscores produced above.\n",
    "        model_inputs = self.tokenizer(examples['source'], max_length=self.config.max_source_length, truncation=True)\n",
    "        labels = self.tokenizer(text_target=examples['target'], max_length=self.config.max_target_length, truncation=True)\n",
    "        model_inputs['labels'] = labels['input_ids']\n",
    "        return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cffae613-40ba-4bed-bc8a-e8f4047dded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. TRAINER CLASS ---\n",
    "class T5NMTTrainer:\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Loading from: {config.model_name}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(config.model_name)\n",
    "        self.model.to(self.device)\n",
    "        self.chrf = evaluate.load('chrf')\n",
    "        \n",
    "    def prepare_data(self, dataset_dict: DatasetDict) -> DatasetDict:\n",
    "        preparator = BilingualDatasetPreparator(self.tokenizer, self.config)\n",
    "        return dataset_dict.map(\n",
    "            preparator.preprocess_function,\n",
    "            batched=True,\n",
    "            batch_size=1000,\n",
    "            remove_columns=dataset_dict['train'].column_names,\n",
    "            num_proc=1, # Keep 1 to be safe, or try 4\n",
    "        )\n",
    "    \n",
    "    def compute_metrics(self, eval_preds):\n",
    "        preds, labels = eval_preds\n",
    "        preds = np.where(preds != -100, preds, self.tokenizer.pad_token_id)\n",
    "        labels = np.where(labels != -100, labels, self.tokenizer.pad_token_id)\n",
    "        decoded_preds = self.tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "        decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "        decoded_labels = [label.strip() for label in decoded_labels]\n",
    "        \n",
    "        bleu_score = sacrebleu.corpus_bleu(decoded_preds, [decoded_labels])\n",
    "        chrf_result = self.chrf.compute(predictions=decoded_preds, references=[[l] for l in decoded_labels])\n",
    "        \n",
    "        # --- SAMPLE TRANSLATIONS REMOVED HERE AS REQUESTED ---\n",
    "        \n",
    "        return {'bleu': bleu_score.score, 'chrf': chrf_result['score']}\n",
    "    \n",
    "    def train(self, tokenized_datasets):\n",
    "        training_args = Seq2SeqTrainingArguments(\n",
    "            output_dir=self.config.output_dir,\n",
    "            num_train_epochs=self.config.num_train_epochs,\n",
    "            per_device_train_batch_size=self.config.per_device_train_batch_size,\n",
    "            per_device_eval_batch_size=self.config.per_device_eval_batch_size,\n",
    "            gradient_accumulation_steps=self.config.gradient_accumulation_steps,\n",
    "            learning_rate=self.config.learning_rate,\n",
    "            weight_decay=self.config.weight_decay,\n",
    "            warmup_steps=self.config.warmup_steps,\n",
    "            fp16=self.config.fp16,\n",
    "            bf16=self.config.bf16,\n",
    "            logging_dir=f\"{self.config.output_dir}/logs\",\n",
    "            logging_steps=self.config.logging_steps,\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=self.config.save_steps,\n",
    "            save_total_limit=self.config.save_total_limit,\n",
    "            eval_strategy=self.config.eval_strategy,\n",
    "            eval_steps=self.config.eval_steps,\n",
    "            predict_with_generate=True,\n",
    "            generation_max_length=self.config.generation_max_length,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"bleu\",\n",
    "            greater_is_better=True,\n",
    "            report_to=[\"tensorboard\"],\n",
    "            push_to_hub=False\n",
    "        )\n",
    "        \n",
    "        data_collator = DataCollatorForSeq2Seq(self.tokenizer, model=self.model, padding=True)\n",
    "        viz_callback = ProgressVisualizationCallback(self.config.output_dir)\n",
    "        \n",
    "        trainer = Seq2SeqTrainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_datasets['train'],\n",
    "            eval_dataset=tokenized_datasets['validation'],\n",
    "            tokenizer=self.tokenizer,\n",
    "            data_collator=data_collator,\n",
    "            compute_metrics=self.compute_metrics,\n",
    "            callbacks=[viz_callback, EarlyStoppingCallback(early_stopping_patience=self.config.early_stopping_patience)]\n",
    "        )\n",
    "        \n",
    "        trainer.train()\n",
    "        print(f\"Saving final model to {self.config.output_dir}...\")\n",
    "        trainer.save_model(self.config.output_dir)\n",
    "        return trainer\n",
    "\n",
    "    def update_model_layers(self, strategy=\"none\"):\n",
    "        # Unfreeze all first\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        encoder = self.model.get_encoder()\n",
    "        num_layers = len(encoder.block)\n",
    "        \n",
    "        if strategy == \"freeze_encoder\":\n",
    "            print(f\"Freezing entire encoder...\")\n",
    "            for param in encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        elif strategy == \"freeze_last_half_encoder\":\n",
    "            start_freeze = num_layers // 2 \n",
    "            print(f\"Freezing last half of encoder (Layers {start_freeze}-{num_layers-1})...\")\n",
    "            for i in range(start_freeze, num_layers):\n",
    "                for param in encoder.block[i].parameters():\n",
    "                    param.requires_grad = False\n",
    "            for param in encoder.final_layer_norm.parameters():\n",
    "                param.requires_grad = False\n",
    "        else:\n",
    "            print(\"Unfreezing all layers (Full Fine-tuning)...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d04be8-d1bc-4a39-aaca-73162c85931b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from: ./t5_phase1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from './t5_phase1' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting and loading data from ./laodata2/train/train.vi and ./laodata2/train/train.lo...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0201f380f2d84d47bae4262b0a5cfe91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/694000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 694000 pairs. Skipped 0 empty/misaligned lines.\n",
      "Segmenting and loading data from ./laodata2/dev/dev.vi and ./laodata2/dev/dev.lo...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162629afab8749cabe290002cf796389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5000 pairs. Skipped 0 empty/misaligned lines.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217ea475d0ca4958b3fb4017f567a032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/694000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- NOTEBOOK 2 EXECUTION ---\n",
    "\n",
    "# 1. Setup Config for Phase 2\n",
    "config = ModelConfig()\n",
    "config.model_name = \"./t5_phase1\"     # <--- LOAD FROM PHASE 1\n",
    "config.output_dir = \"./t5_phase2\"     # <--- SAVE TO PHASE 2\n",
    "config.num_train_epochs = 3                    # Typically faster phases need fewer epochs\n",
    "config.learning_rate = 5e-5\n",
    "\n",
    "# 2. Initialize\n",
    "trainer_wrapper = T5NMTTrainer(config)\n",
    "\n",
    "# 3. Load Data (Same as before)\n",
    "preparator = BilingualDatasetPreparator(trainer_wrapper.tokenizer, config)\n",
    "train_ds = preparator.create_dataset_from_files('./laodata2/train/train.vi', './laodata2/train/train.lo')\n",
    "val_ds = preparator.create_dataset_from_files('./laodata2/dev/dev.vi', './laodata2/dev/dev.lo')\n",
    "dataset_dict = DatasetDict({'train': train_ds, 'validation': val_ds})\n",
    "\n",
    "# 4. Tokenize\n",
    "tokenized_datasets = trainer_wrapper.prepare_data(dataset_dict)\n",
    "\n",
    "# 5. Set Strategy & Train\n",
    "print(\"--- STARTING PHASE 2 ---\")\n",
    "trainer_wrapper.update_model_layers(\"freeze_encoder\") # <--- FREEZE STRATEGY\n",
    "trainer = trainer_wrapper.train(tokenized_datasets)\n",
    "\n",
    "print(\"PHASE 2 COMPLETE. Model saved to:\", config.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b908f264-bdd7-41cd-90c9-4ef9306588db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data from:\n",
      "  VI: ./laodata2/test/test_vi.txt\n",
      "  LO: ./laodata2/test/test_lo.txt\n",
      "Segmenting and loading data from ./laodata2/test/test_vi.txt and ./laodata2/test/test_lo.txt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d9e382a69e46ce9efd514cf59d1cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 pairs. Skipped 0 empty/misaligned lines.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba01650d43a4a88b313c6b070b80019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running generation on test set (this may take a moment)...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "That's 100 lines that end in a tokenized period ('.')\n",
      "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL TEST SET METRICS\n",
      "BLEU: 38.79\n",
      "chrF: 52.16\n",
      "Loss: 0.8164\n",
      "\n",
      "--- RANDOMLY SELECTED SAMPLES (10) ---\n",
      "Example #654:\n",
      "Input (LO) : ການປະສານງານ ການທົດສອບ ການຍອມຮັບ ຢູ່ ທີ່ ປະມານ ເສົາ 1312 - 1313 ( ສ່ວນ ທາງດ່ວນ ວິງ ຫາວ - ຟານ ທຽດ).\n",
      "Ref (VI)   : Công_tác phối_hợp nghiệm_thu tại khoảng cột 1312 - 1313 ( đoạn cao_tốc Vĩnh_Hảo - Phan_Thiết ) .\n",
      "Pred (VI)  : Điều_phối thẩm_định tại khoảng cầu 1312 - 1313 ( đoạn cao_tốc Vĩnh_Hảo - Phan_Thiết ) .\n",
      "--------------------------------------------------\n",
      "Example #114:\n",
      "Input (LO) : ຊາວບ້ານ ໄດ້ ໂຕ້ວາທີ ກ່ຽວກັບ ຄວາມຖືກຕ້ອງ ຂອງ ຕົວລະຄອນ ແລະ ຊື່ ເຫດການ ໃນ ເລື່ອງລາວຈີນ , ເຊິ່ງ ເຮັດໃຫ້ເກີດ ການ ໂຕ້ວາທີ ທາງ ວິຊາການ .\n",
      "Ref (VI)   : Nói truyện Tàu không đúng tên nhân_vật và sự_kiện là đề_tài tranh_cãi đầy tính bác_học của dân trong làng .\n",
      "Pred (VI)  : Người dân đã tranh_cãi về sự đúng_đắn của nhân_vật và tên sự_việc trong câu_chuyện Trung_Quốc , gây ra tranh_cãi kỹ_thuật .\n",
      "--------------------------------------------------\n",
      "Example #25:\n",
      "Input (LO) : ການເພີ່ມຂຶ້ນ ຂອງ ລະດັບ ຮໍໂມນ ເອ ສ ໂຕ ຣ ເຈນ ພ້ອມ ກັບ ການໄຫຼ ວຽນ ຂອງ ເລືອດ ທີ່ເພີ່ມຂຶ້ນ ເຮັດໃຫ້ ຜົມ ຂອງ ທ່ານ ມີ ສຸຂະພາບດີ , ຍາວ ແລະ ຫນາ ຂຶ້ນ .\n",
      "Ref (VI)   : Sự gia_tăng nồng_độ hormone estrogen cùng lưu_lượng máu tăng cao khiến mái_tóc bạn trở_nên khỏe_mạnh , dài và dày .\n",
      "Pred (VI)  : Việc tăng hormone estrogen cùng với sự chuyển_đổi máu tăng , tóc của bạn sẽ được sức_khỏe , dài và lớn hơn .\n",
      "--------------------------------------------------\n",
      "Example #759:\n",
      "Input (LO) : ແຕ່ ມັນ ຈະ ເປັນ ສິ່ງ ທີ່ ຫນ້າ ອັດສະຈັນ ກວ່ານັ້ນ ອີກ ຖ້າ Messi ສາມາດ ສິ້ນສຸດ ອາຊີບອັນ ຮຸ່ງໂລດ ຂອງ ລາວ ໃນ ເຕະບານ ໂລກ ໂດຍ ການຍົກ ຖ້ວຍ ລາງວັນ ແລະ ພ້ອມ ກັບ ລາງວັນ ສ່ວນ ບຸກຄົນ ທີ່ມີ ຊື່ສຽງ .\n",
      "Ref (VI)   : Nhưng sẽ còn tuyệt_vời hơn nữa nếu Messi đóng lại sự_nghiệp vinh_quang của anh ở World_Cup bằng cách nâng cao cúp vô_địch và cùng với đó là những giải_thưởng cá_nhân cao_quý .\n",
      "Pred (VI)  : Nhưng sẽ không còn đáng ngạc_nhiên hơn nếu Messi có_thể kết_thúc sự_nghiệp ấn_tượng ở World_Cup bằng cách nâng tấm giải và cùng với những giải_thưởng cá_nhân nổi_tiếng .\n",
      "--------------------------------------------------\n",
      "Example #281:\n",
      "Input (LO) : ອີງ ຕາມ ນັກ ສະແດງ ຫຼາຍ ຄົນ , ທີມງານ ຖ່າຍຮູບເງົາ ໄດ້ ປະເຊີນ ກັບ ຄວາມຫຍຸ້ງຍາກ ຫຼາຍ ຢ່າງ ໃນ ລະຫວ່າງ ການຖ່າຍທໍາ , ໂດຍ ມີ ເຖິງ 20 ຄົນໃນ ທີມງານ ຕິດເຊື້ອ COVID-19 ໃນ ຈຸດ ຫນຶ່ງ .\n",
      "Ref (VI)   : Theo chia_sẻ của nhiều diễn ᴠiên , trong suốt thời_gian ghi_hình , nhóm làm phim gặp không ít khó_khăn , thậm_chí có lúc 20 người trong đoàn phim mắc COVID - 19 .\n",
      "Pred (VI)  : Theo nhiều diễn_viên , đội_ngũ phim đã gặp nhiều khó_khăn trong quá_trình quay , trong đó có đến 20 người trong đội_ngũ nhiễm COVID - 19 .\n",
      "--------------------------------------------------\n",
      "Example #250:\n",
      "Input (LO) : ເຈົ້າ ສາມາດ ຮູ້ສຶກ ເຖິງ ເປືອກໄຂ່ ; ຖ້າມັນ ຮູ້ສຶກ ຫຍາບ ຫຼື ເປັນ ຂຸຂະ ເລັກນ້ອຍ , ໄຂ່ ຍັງ ສົດ ຢູ່ , ໃນ ຂະນະທີ່ເປືອກ ລຽບ ຫມາຍຄວາມ ວ່າ ໄຂ່ ຖືກ ເກັບໄວ້ ເປັນ ເວລາດົນນານ .\n",
      "Ref (VI)   : Bạn sờ vào vỏ trứng , nếu cảm_thấy vỏ trứng hơi nhám , sần_sùi là trứng tươi , còn vỏ trứng láng là trứng đã để lâu ngày .\n",
      "Pred (VI)  : Bạn có_thể cảm_nhận được những tấm sợi , nếu cảm_thấy sợi , sợi nhỏ , sợi vẫn tươi , trong khi những tấm sợi sẽ được giữ lâu .\n",
      "--------------------------------------------------\n",
      "Example #228:\n",
      "Input (LO) : ຂໍ້ມູນ ທີ່ ຫາຍາກ ກ່ຽວກັບ ຜົວ ຂອງ ມິງ ຮ ั่ง: ລາວ ເປັນ ຜູ້ນໍາ ຂອງ ບໍລິສັດ ໃຫຍ່ ໃນ ເຂດ ສາມ ຫຼ່ຽມ ປາກ ແມ່ນໍ້າ ຂອງ , ແລະ ບຸກຄະລິກ ຂອງ ລາວ ໄດ້ ຖືກ ເປີດເຜີຍ ຜ່ານ ຄໍ າ ເວົ້າ ພຽງ ຄໍ າ ດຽວ !\n",
      "Ref (VI)   : Thêm thông_tin hiếm về chồng Minh_Hằng : Là lãnh_đạo công_ty lớn ở miền Tây , tính_cách lộ rõ qua 1 câu nói !\n",
      "Pred (VI)  : Dữ_liệu hiếm_hoi về chồng Minh_Hằng : Anh là lãnh_đạo công_ty lớn ở ĐBSCL , tính_cách của anh đã được công_bố qua một câu nói !\n",
      "--------------------------------------------------\n",
      "Example #142:\n",
      "Input (LO) : ເຖິງວ່າ ຈະ ເກີດມາ ໃນ ຄອບຄົວ ທີ່ ຖ່ອມຕົວ , ແຕ່ ພວກເຂົາ ກໍ່ໄດ້ ຮັບ ຄວາມຮູ້ ຕັ້ງແຕ່ ຍັງ ນ້ອຍ ແລະ ມີ ຄວາມເຂົ້າໃຈສູງ ກວ່າ ຄົນອື່ນ .\n",
      "Ref (VI)   : Dù sinh ra ở gia_đình không khá_giả nhưn họ sớm được khai sáng , hiểu_biết hơn người .\n",
      "Pred (VI)  : Dù sinh ra trong một gia_đình tự_do nhưng họ cũng được học_hỏi từ nhỏ và nắm_bắt hơn mọi người .\n",
      "--------------------------------------------------\n",
      "Example #754:\n",
      "Input (LO) : ອີງ ຕາມ ທ່ານ Hoat , ພາຍໃຕ້ ໂຄງການພັດທະນາທີ່ຢູ່ອາໄສ ຂອງ ແຂວງ ຈົນ ຮອດ ປີ 2025 ແລະ ການວາງ ທິດທາງ ຈົນ ຮອດ ປີ 2030 , ຄວາມຕ້ອງການ ຂອງ ແຂວງ ພາຍໃນ ປີ 2030 ແມ່ນ ການພັດທະນາທີ່ຢູ່ອາໄສ ສັງຄົມ ປະມານ 475,000 ຕາແມັດ .\n",
      "Ref (VI)   : Theo ông Hoạt , theo Chương_trình phát_triển nhà ở tỉnh đến năm 2025 và định_hướng đến năm 2030 , nhu_cầu đến năm 2030 của tỉnh là phát_triển khoảng 475.000 m sàn nhà ở xã_hội .\n",
      "Pred (VI)  : Theo ông Hòa , theo chương_trình phát_triển nhà ở tỉnh đến năm 2025 và định_hướng đến năm 2030 , nhu_cầu của tỉnh trong năm 2030 là phát_triển khoảng 475.000 m2 nhà ở xã_hội .\n",
      "--------------------------------------------------\n",
      "Example #104:\n",
      "Input (LO) : ພວກເຂົາ ໄດ້ ດໍາເນີນການຕາມ ຂັ້ນຕອນ ການຊື້ ເຮືອນ ( ສັນຍາ ຊື້ຂາຍ ທີ່ມີ ຜູ້ຮັບຮອງ ທາງ ກົດຫມາຍ ເນື່ອງຈາກ ເຮືອນ ບໍ່ມີ ໃບ ຢັ້ງຢືນ ການອອກ ໃບ ຕາດິນ ) ຜ່ານ ຜູ້ຊາຍ ຄົນ ຫນຶ່ງ ຊື່ Q . A ., ຜູ້ ທີ່ ອ້າງ ວ່າເປັນ ເຈົ້າຂອງ ເຮືອນ ແລະ ກ່າວ ວ່າ ລາວ ເປັນ ຜູ້ຊາຍ ໂສດ ທີ່ ໄດ້ ຢ່າຮ້າງ ກັບ ພັນລະຍາ ຂອງ ລາວ ມາ ຫຼາຍ ປີແລ້ວ .\n",
      "Ref (VI)   : Họ tiến_hành thủ_tục mua nhà ( mua_bán vi bằng do nhà không có sổ_đỏ ) , qua một người đàn_ông tên Q. A. , xưng là chủ sở_hữu căn nhà và nói rằng mình sống đơn_thân , đã ly_hôn vợ nhiều năm nay .\n",
      "Pred (VI)  : Họ đã thực_hiện theo quy_trình mua nhà ( hợp_đồng mua nhà có chứng_nhận pháp_lý do nhà không có giấy chứng_nhận sổ_đỏ ) thông_qua một người đàn_ông tên Q. A. , từng tuyên_bố là chủ nhà và cho biết ông là một người đàn_ông tình_tử , đã ly_hôn với vợ \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_on_test_set(trainer, test_vi_path, test_lo_path, num_samples=10):\n",
    "    print(f\"Loading test data from:\\n  VI: {test_vi_path}\\n  LO: {test_lo_path}\")\n",
    "    \n",
    "    # 1. Load the Test Data\n",
    "    test_ds = preparator.create_dataset_from_files(test_vi_path, test_lo_path)\n",
    "    \n",
    "    # 2. Tokenize\n",
    "    test_dataset_dict = DatasetDict({'test': test_ds})\n",
    "    \n",
    "    tokenized_test = test_dataset_dict.map(\n",
    "        preparator.preprocess_function,\n",
    "        batched=True,\n",
    "        batch_size=1000,\n",
    "        remove_columns=test_dataset_dict['test'].column_names,\n",
    "        num_proc=1, \n",
    "    )\n",
    "    \n",
    "    print(\"\\nRunning generation on test set (this may take a moment)...\")\n",
    "    \n",
    "    # 3. Predict (Run Inference)\n",
    "    test_results = trainer.predict(tokenized_test['test'])\n",
    "    \n",
    "    # 4. Print Metrics\n",
    "    print(\"\\nFINAL TEST SET METRICS\")\n",
    "    print(f\"BLEU: {test_results.metrics['test_bleu']:.2f}\")\n",
    "    print(f\"chrF: {test_results.metrics['test_chrf']:.2f}\")\n",
    "    print(f\"Loss: {test_results.metrics['test_loss']:.4f}\")\n",
    "    \n",
    "    # 5. Show Sample Translations\n",
    "    # Predictions and labels from trainer.predict are already padded/rectangular,\n",
    "    # but we handle them safely anyway.\n",
    "    preds = np.where(test_results.predictions != -100, test_results.predictions, trainer.tokenizer.pad_token_id)\n",
    "    labels = np.where(test_results.label_ids != -100, test_results.label_ids, trainer.tokenizer.pad_token_id)\n",
    "    \n",
    "    decoded_preds = trainer.tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = trainer.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # --- FIX FOR THE ERROR ---\n",
    "    # We decode the input_ids directly from the dataset. \n",
    "    # batch_decode handles jagged lists of lists perfectly fine!\n",
    "    input_ids = tokenized_test['test']['input_ids']\n",
    "    decoded_inputs = trainer.tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n--- RANDOMLY SELECTED SAMPLES ({num_samples}) ---\")\n",
    "    indices = random.sample(range(len(decoded_preds)), min(num_samples, len(decoded_preds)))\n",
    "    \n",
    "    for i in indices:\n",
    "        print(f\"Example #{i}:\")\n",
    "        print(f\"Input (LO) : {decoded_inputs[i].replace('translate Laos to Vietnamese: ', '')}\")\n",
    "        print(f\"Ref (VI)   : {decoded_labels[i]}\")\n",
    "        print(f\"Pred (VI)  : {decoded_preds[i]}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# --- CONFIGURATION FOR TEST ---\n",
    "TEST_VI_PATH = './laodata2/test/test_vi.txt' \n",
    "TEST_LO_PATH = './laodata2/test/test_lo.txt'\n",
    "\n",
    "# Run the evaluation\n",
    "evaluate_on_test_set(trainer, TEST_VI_PATH, TEST_LO_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
