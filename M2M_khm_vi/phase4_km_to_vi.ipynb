{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd13816-7db1-40ee-8419-b5e227f76b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.10/site-packages (4.57.3)\n",
      "Requirement already satisfied: sentencepiece in ./.local/lib/python3.10/site-packages (0.2.1)\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.10/site-packages (4.4.2)\n",
      "Requirement already satisfied: sacrebleu in ./.local/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: accelerate in ./.local/lib/python3.10/site-packages (1.12.0)\n",
      "Requirement already satisfied: pyvi in ./.local/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from torch) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.local/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.local/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.local/lib/python3.10/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.local/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.local/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.local/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.local/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.local/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.local/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.local/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.local/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.local/lib/python3.10/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.local/lib/python3.10/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.local/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.local/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.local/lib/python3.10/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.local/lib/python3.10/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.10/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.local/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.10/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in ./.local/lib/python3.10/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in ./.local/lib/python3.10/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.10/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.10/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in ./.local/lib/python3.10/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: portalocker in ./.local/lib/python3.10/site-packages (from sacrebleu) (3.2.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in ./.local/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in ./.local/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in ./.local/lib/python3.10/site-packages (from sacrebleu) (6.0.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: scikit-learn in ./.local/lib/python3.10/site-packages (from pyvi) (1.7.2)\n",
      "Requirement already satisfied: sklearn-crfsuite in ./.local/lib/python3.10/site-packages (from pyvi) (0.5.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.local/lib/python3.10/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.local/lib/python3.10/site-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.local/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.local/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.local/lib/python3.10/site-packages (from scikit-learn->pyvi) (3.6.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.7 in ./.local/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers sentencepiece datasets sacrebleu accelerate pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5761b115-1554-4d7d-b1a4-cd662dd46def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA H200\n",
      "VRAM: 150.0217344 GB\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Setup and imports\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from transformers import (\n",
    "    M2M100ForConditionalGeneration,\n",
    "    M2M100Tokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoTokenizer\n",
    ")\n",
    "import random\n",
    "\n",
    "from pyvi import ViTokenizer\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(\"VRAM:\", torch.cuda.get_device_properties(0).total_memory / 1e9, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5ecb800-5be8-4f26-93f5-fbbbe6cd16b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Khmer tokenizer loaded successfully!\n",
      "Vietnamese and Khmer tokenizers loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Khmer tokenizer\n",
    "# Load Khmer tokenizer from Hugging Face\n",
    "khmer_word_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"khopilot/km-tokenizer-khmer\", \n",
    "    use_fast=False\n",
    ")\n",
    "print(\"Khmer tokenizer loaded successfully!\")\n",
    "\n",
    "# Cell 3b: Define tokenization functions\n",
    "def tokenize_vietnamese(text):\n",
    "    \"\"\"Tokenize Vietnamese text using PyVi\"\"\"\n",
    "    try:\n",
    "        return ViTokenizer.tokenize(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error tokenizing Vietnamese: {e}\")\n",
    "        return text\n",
    "\n",
    "def tokenize_khmer(text):\n",
    "    \"\"\"Tokenize Khmer text using khopilot/km-tokenizer-khmer\"\"\"\n",
    "    try:\n",
    "        tokens = khmer_word_tokenizer.tokenize(text)\n",
    "        return \" \".join(tokens)\n",
    "    except Exception as e:\n",
    "        print(f\"Error tokenizing Khmer: {e}\")\n",
    "        return text\n",
    "\n",
    "def tokenize_batch_vietnamese(texts):\n",
    "    \"\"\"Batch tokenize Vietnamese texts\"\"\"\n",
    "    print(f\"Tokenizing {len(texts)} Vietnamese texts...\")\n",
    "    results = []\n",
    "    for i, text in enumerate(texts):\n",
    "        results.append(tokenize_vietnamese(text))\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print(f\"  Processed {i + 1}/{len(texts)} Vietnamese texts\")\n",
    "    return results\n",
    "\n",
    "def tokenize_batch_khmer(texts):\n",
    "    \"\"\"Batch tokenize Khmer texts\"\"\"\n",
    "    print(f\"Tokenizing {len(texts)} Khmer texts...\")\n",
    "    results = []\n",
    "    for i, text in enumerate(texts):\n",
    "        results.append(tokenize_khmer(text))\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print(f\"  Processed {i + 1}/{len(texts)} Khmer texts\")\n",
    "    return results\n",
    "\n",
    "print(\"Vietnamese and Khmer tokenizers loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24993ec2-666f-4771-b95e-ddd4a994ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = \"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aae468b-46e4-4cfc-b110-bfddfd59055b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Phase 3 model...\n",
      "Model parameters: 483.9M\n",
      "Phase 3 model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 3: Load Phase 3 Model\n",
    "# ============================================================\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "\n",
    "print(\"Loading Phase 3 model...\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./km_to_vi/phase3/best\").cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./km_to_vi/phase3/best\")\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.1f}M\")\n",
    "print(\"Phase 3 model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1d0785-e3e9-4d60-948f-5f049f55df05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unfreezing all parameters...\n",
      "\n",
      "======================================================================\n",
      "PARAMETER STATISTICS\n",
      "======================================================================\n",
      "Total params        : 483.9M\n",
      "Trainable params    : 483.9M\n",
      "  - Encoder         : 201.6M\n",
      "  - Decoder         : 151.2M\n",
      "Trainable %         : 100.0%\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 4: Unfreeze ALL Parameters\n",
    "# ============================================================\n",
    "print(\"\\nUnfreezing all parameters...\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Verify\n",
    "total, trainable = 0, 0\n",
    "encoder_trainable, decoder_trainable = 0, 0\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    n = param.numel()\n",
    "    total += n\n",
    "    \n",
    "    if param.requires_grad:\n",
    "        trainable += n\n",
    "        if \"encoder\" in name:\n",
    "            encoder_trainable += n\n",
    "        elif \"decoder\" in name:\n",
    "            decoder_trainable += n\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PARAMETER STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total params        : {total/1e6:.1f}M\")\n",
    "print(f\"Trainable params    : {trainable/1e6:.1f}M\")\n",
    "print(f\"  - Encoder         : {encoder_trainable/1e6:.1f}M\")\n",
    "print(f\"  - Decoder         : {decoder_trainable/1e6:.1f}M\")\n",
    "print(f\"Trainable %         : 100.0%\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fac730b-90c3-49cd-a487-fecb9908bbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing Vietnamese texts...\n",
      "Tokenizing 599999 Vietnamese texts...\n",
      "  Processed 10000/599999 Vietnamese texts\n",
      "  Processed 20000/599999 Vietnamese texts\n",
      "  Processed 30000/599999 Vietnamese texts\n",
      "  Processed 40000/599999 Vietnamese texts\n",
      "  Processed 50000/599999 Vietnamese texts\n",
      "  Processed 60000/599999 Vietnamese texts\n",
      "  Processed 70000/599999 Vietnamese texts\n",
      "  Processed 80000/599999 Vietnamese texts\n",
      "  Processed 90000/599999 Vietnamese texts\n",
      "  Processed 100000/599999 Vietnamese texts\n",
      "  Processed 110000/599999 Vietnamese texts\n",
      "  Processed 120000/599999 Vietnamese texts\n",
      "  Processed 130000/599999 Vietnamese texts\n",
      "  Processed 140000/599999 Vietnamese texts\n",
      "  Processed 150000/599999 Vietnamese texts\n",
      "  Processed 160000/599999 Vietnamese texts\n",
      "  Processed 170000/599999 Vietnamese texts\n",
      "  Processed 180000/599999 Vietnamese texts\n",
      "  Processed 190000/599999 Vietnamese texts\n",
      "  Processed 200000/599999 Vietnamese texts\n",
      "  Processed 210000/599999 Vietnamese texts\n",
      "  Processed 220000/599999 Vietnamese texts\n",
      "  Processed 230000/599999 Vietnamese texts\n",
      "  Processed 240000/599999 Vietnamese texts\n",
      "  Processed 250000/599999 Vietnamese texts\n",
      "  Processed 260000/599999 Vietnamese texts\n",
      "  Processed 270000/599999 Vietnamese texts\n",
      "  Processed 280000/599999 Vietnamese texts\n",
      "  Processed 290000/599999 Vietnamese texts\n",
      "  Processed 300000/599999 Vietnamese texts\n",
      "  Processed 310000/599999 Vietnamese texts\n",
      "  Processed 320000/599999 Vietnamese texts\n",
      "  Processed 330000/599999 Vietnamese texts\n",
      "  Processed 340000/599999 Vietnamese texts\n",
      "  Processed 350000/599999 Vietnamese texts\n",
      "  Processed 360000/599999 Vietnamese texts\n",
      "  Processed 370000/599999 Vietnamese texts\n",
      "  Processed 380000/599999 Vietnamese texts\n",
      "  Processed 390000/599999 Vietnamese texts\n",
      "  Processed 400000/599999 Vietnamese texts\n",
      "  Processed 410000/599999 Vietnamese texts\n",
      "  Processed 420000/599999 Vietnamese texts\n",
      "  Processed 430000/599999 Vietnamese texts\n",
      "  Processed 440000/599999 Vietnamese texts\n",
      "  Processed 450000/599999 Vietnamese texts\n",
      "  Processed 460000/599999 Vietnamese texts\n",
      "  Processed 470000/599999 Vietnamese texts\n",
      "  Processed 480000/599999 Vietnamese texts\n",
      "  Processed 490000/599999 Vietnamese texts\n",
      "  Processed 500000/599999 Vietnamese texts\n",
      "  Processed 510000/599999 Vietnamese texts\n",
      "  Processed 520000/599999 Vietnamese texts\n",
      "  Processed 530000/599999 Vietnamese texts\n",
      "  Processed 540000/599999 Vietnamese texts\n",
      "  Processed 550000/599999 Vietnamese texts\n",
      "  Processed 560000/599999 Vietnamese texts\n",
      "  Processed 570000/599999 Vietnamese texts\n",
      "  Processed 580000/599999 Vietnamese texts\n",
      "  Processed 590000/599999 Vietnamese texts\n",
      "Tokenizing Khmer texts...\n",
      "Tokenizing 599999 Khmer texts...\n",
      "  Processed 10000/599999 Khmer texts\n",
      "  Processed 20000/599999 Khmer texts\n",
      "  Processed 30000/599999 Khmer texts\n",
      "  Processed 40000/599999 Khmer texts\n",
      "  Processed 50000/599999 Khmer texts\n",
      "  Processed 60000/599999 Khmer texts\n",
      "  Processed 70000/599999 Khmer texts\n",
      "  Processed 80000/599999 Khmer texts\n",
      "  Processed 90000/599999 Khmer texts\n",
      "  Processed 100000/599999 Khmer texts\n",
      "  Processed 110000/599999 Khmer texts\n",
      "  Processed 120000/599999 Khmer texts\n",
      "  Processed 130000/599999 Khmer texts\n",
      "  Processed 140000/599999 Khmer texts\n",
      "  Processed 150000/599999 Khmer texts\n",
      "  Processed 160000/599999 Khmer texts\n",
      "  Processed 170000/599999 Khmer texts\n",
      "  Processed 180000/599999 Khmer texts\n",
      "  Processed 190000/599999 Khmer texts\n",
      "  Processed 200000/599999 Khmer texts\n",
      "  Processed 210000/599999 Khmer texts\n",
      "  Processed 220000/599999 Khmer texts\n",
      "  Processed 230000/599999 Khmer texts\n",
      "  Processed 240000/599999 Khmer texts\n",
      "  Processed 250000/599999 Khmer texts\n",
      "  Processed 260000/599999 Khmer texts\n",
      "  Processed 270000/599999 Khmer texts\n",
      "  Processed 280000/599999 Khmer texts\n",
      "  Processed 290000/599999 Khmer texts\n",
      "  Processed 300000/599999 Khmer texts\n",
      "  Processed 310000/599999 Khmer texts\n",
      "  Processed 320000/599999 Khmer texts\n",
      "  Processed 330000/599999 Khmer texts\n",
      "  Processed 340000/599999 Khmer texts\n",
      "  Processed 350000/599999 Khmer texts\n",
      "  Processed 360000/599999 Khmer texts\n",
      "  Processed 370000/599999 Khmer texts\n",
      "  Processed 380000/599999 Khmer texts\n",
      "  Processed 390000/599999 Khmer texts\n",
      "  Processed 400000/599999 Khmer texts\n",
      "  Processed 410000/599999 Khmer texts\n",
      "  Processed 420000/599999 Khmer texts\n",
      "  Processed 430000/599999 Khmer texts\n",
      "  Processed 440000/599999 Khmer texts\n",
      "  Processed 450000/599999 Khmer texts\n",
      "  Processed 460000/599999 Khmer texts\n",
      "  Processed 470000/599999 Khmer texts\n",
      "  Processed 480000/599999 Khmer texts\n",
      "  Processed 490000/599999 Khmer texts\n",
      "  Processed 500000/599999 Khmer texts\n",
      "  Processed 510000/599999 Khmer texts\n",
      "  Processed 520000/599999 Khmer texts\n",
      "  Processed 530000/599999 Khmer texts\n",
      "  Processed 540000/599999 Khmer texts\n",
      "  Processed 550000/599999 Khmer texts\n",
      "  Processed 560000/599999 Khmer texts\n",
      "  Processed 570000/599999 Khmer texts\n",
      "  Processed 580000/599999 Khmer texts\n",
      "  Processed 590000/599999 Khmer texts\n",
      "Total dataset size: 599999 examples\n",
      "Train dataset: 595999 examples (for training)\n",
      "Dev dataset  : 3000 examples (for validation during training)\n",
      "Test dataset : 1000 examples (for final evaluation)\n",
      "\n",
      "Data split and shuffle completed.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Load and prepare data\n",
    "\n",
    "def load_parallel(src_file, tgt_file):\n",
    "    with open(src_file, encoding=\"utf-8\") as f:\n",
    "        src = [l.strip() for l in f]\n",
    "    with open(tgt_file, encoding=\"utf-8\") as f:\n",
    "        tgt = [l.strip() for l in f]\n",
    "    \n",
    "    assert len(src) == len(tgt)\n",
    "\n",
    "    print(\"Tokenizing Vietnamese texts...\")\n",
    "    src_tokenized = tokenize_batch_khmer(src)\n",
    "    \n",
    "    print(\"Tokenizing Khmer texts...\")\n",
    "    tgt_tokenized = tokenize_batch_vietnamese(tgt) \n",
    "    \n",
    "    return Dataset.from_dict({\n",
    "        \"src_text\": src_tokenized,\n",
    "        \"tgt_text\": tgt_tokenized\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "# Load data from train.khm and train.vi\n",
    "full_dataset = load_parallel(\n",
    "    f\"{DATA_DIR}/train_khmer_to_vi_shuf.khm\",\n",
    "    f\"{DATA_DIR}/train_khmer_to_vi_shuf.vi\"\n",
    ")\n",
    "\n",
    "print(f\"Total dataset size: {len(full_dataset)} examples\")\n",
    "\n",
    "# Split dataset\n",
    "test_size = 1000\n",
    "dev_size = 3000\n",
    "\n",
    "test_start_idx = len(full_dataset) - test_size\n",
    "dev_start_idx = test_start_idx - dev_size\n",
    "\n",
    "test_dataset = full_dataset.select(range(test_start_idx, len(full_dataset)))\n",
    "dev_dataset = full_dataset.select(range(dev_start_idx, test_start_idx))\n",
    "train_dataset = full_dataset.select(range(0, dev_start_idx))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(seed=42)\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)} examples (for training)\")\n",
    "print(f\"Dev dataset  : {len(dev_dataset)} examples (for validation during training)\")\n",
    "print(f\"Test dataset : {len(test_dataset)} examples (for final evaluation)\")\n",
    "print(\"\\nData split and shuffle completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3b9e1f5-176a-4bf2-9a84-8d674eb347f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Preprocessing function\n",
    "MAX_LEN = 256\n",
    "\n",
    "def preprocess(batch):\n",
    "    tokenizer.src_lang = \"km\"  # Changed from \"lo\" to \"km\" for Khmer\n",
    "    tokenizer.tgt_lang = \"vi\"\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        batch[\"src_text\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            batch[\"tgt_text\"],\n",
    "            truncation=True,\n",
    "            max_length=MAX_LEN\n",
    "        )\n",
    "\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59e725b7-9ac7-49d7-ba82-9905c6bbbf74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee9db6d1d5549ecb55defdd0af803e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/595999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164e5a15fe6849a5b85e7a726d26f9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Apply preprocessing\n",
    "train_dataset = train_dataset.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    num_proc=8\n",
    ")\n",
    "\n",
    "dev_dataset = dev_dataset.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=dev_dataset.column_names,\n",
    "    num_proc=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c36f3c1-792e-4ece-8268-07135281cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: Data Collator\n",
    "# ============================================================\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa1778f3-41e6-4c07-a1dc-d6913f31271f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training configuration:\n",
      "Effective batch size: 512\n",
      "Learning rate: 5e-05\n",
      "Epochs: 12\n",
      "Label smoothing: 0.15\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 8: Training Arguments\n",
    "# ============================================================\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./km_to_vi/phase4\",\n",
    "    \n",
    "    # Evaluation & Saving\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    \n",
    "    # Logging\n",
    "    logging_steps=100,    \n",
    "    # Batch size\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=4,\n",
    "    \n",
    "    # Learning rate - VERY LOW for full fine-tuning\n",
    "    learning_rate=5e-5 ,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_ratio=0.08,\n",
    "    \n",
    "    # Regularization - STRONGER to prevent overfitting\n",
    "    weight_decay=0.1,\n",
    "    max_grad_norm=0.4,  # Stricter clipping\n",
    "    \n",
    "    # Training\n",
    "    num_train_epochs=12,\n",
    "    \n",
    "    # FP16\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "\n",
    "    # Speed\n",
    "    group_by_length=True,\n",
    "    dataloader_num_workers=8,\n",
    "    dataloader_pin_memory=True,\n",
    "    \n",
    "    \n",
    "    # Best model\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    \n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "print(\"\\nTraining configuration:\")\n",
    "print(f\"Effective batch size: {128 * 4}\")\n",
    "print(f\"Learning rate: {5e-5 }\")\n",
    "print(f\"Epochs: {12}\")\n",
    "print(f\"Label smoothing: 0.15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c17a20a3-e687-4abf-9ad2-37814d4b0c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6843/2995964508.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 9: Create Trainer\n",
    "# ============================================================\n",
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=dev_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[\n",
    "            EarlyStoppingCallback(early_stopping_patience=6)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36148642-bead-49ae-8ad6-2e8ee3d0b763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STARTING PHASE 4: FULL FINE-TUNING\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13980' max='13980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13980/13980 2:00:53, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.679800</td>\n",
       "      <td>0.694644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.702900</td>\n",
       "      <td>0.698146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.688400</td>\n",
       "      <td>0.691658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.684700</td>\n",
       "      <td>0.684160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.656400</td>\n",
       "      <td>0.677242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.657600</td>\n",
       "      <td>0.671043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.651900</td>\n",
       "      <td>0.667021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.629400</td>\n",
       "      <td>0.666786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.633500</td>\n",
       "      <td>0.663253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.607900</td>\n",
       "      <td>0.661816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.608100</td>\n",
       "      <td>0.655212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.580700</td>\n",
       "      <td>0.654980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.588900</td>\n",
       "      <td>0.649732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.587100</td>\n",
       "      <td>0.652200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.568500</td>\n",
       "      <td>0.653324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.572500</td>\n",
       "      <td>0.647342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.554300</td>\n",
       "      <td>0.648690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.554700</td>\n",
       "      <td>0.646116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.537000</td>\n",
       "      <td>0.646083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.544700</td>\n",
       "      <td>0.644899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.538800</td>\n",
       "      <td>0.642667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.529200</td>\n",
       "      <td>0.642511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.529600</td>\n",
       "      <td>0.643792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.518900</td>\n",
       "      <td>0.644911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.517300</td>\n",
       "      <td>0.642694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.511200</td>\n",
       "      <td>0.642862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.510500</td>\n",
       "      <td>0.641664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING COMPLETED\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 10: Train\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING PHASE 4: FULL FINE-TUNING\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "609fc963-edba-46d5-b652-0cb976048f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving best model...\n",
      "Model saved!!! \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 11: Save Model\n",
    "# ============================================================\n",
    "print(\"\\nSaving best model...\")\n",
    "trainer.save_model(\"./km_to_vi/phase4/best\")\n",
    "tokenizer.save_pretrained(\"./km_to_vi/phase4/best\")\n",
    "print(f\"Model saved!!! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95504577-5450-41ea-a473-c27d069a922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 12: Evaluation Function\n",
    "# ============================================================\n",
    "def translate_batch(texts, model, tokenizer, batch_size=32):\n",
    "    \"\"\"Batch translation for speed\"\"\"\n",
    "    model.eval()\n",
    "    tokenizer.src_lang = \"km\"\n",
    "    tokenizer.tgt_lang = \"vi\"\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        \n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=256\n",
    "        ).to(\"cuda\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            gen = model.generate(\n",
    "                **inputs,\n",
    "                forced_bos_token_id=tokenizer.get_lang_id(\"vi\"),\n",
    "                num_beams=5,\n",
    "                max_length=256\n",
    "            )\n",
    "        \n",
    "        texts_out = tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
    "        outputs.extend(texts_out)\n",
    "        \n",
    "        if (i // batch_size + 1) % 10 == 0:\n",
    "            print(f\"Translated {i+len(batch)}/{len(texts)}\")\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f30a369c-2dd3-4c39-bd93-2fb8017cdcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set size: 1000 examples\n",
      "\n",
      "Translating test set...\n",
      "\n",
      "Translating test set...\n",
      "Translated 320/1000\n",
      "Translated 640/1000\n",
      "Translated 960/1000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 13: Evaluate on Test Set\n",
    "# ============================================================\n",
    "# Load test data\n",
    "# Lấy dữ liệu test từ test_dataset (đã chia từ train.vi/train.lo)\n",
    "test_khm = test_dataset[\"src_text\"]\n",
    "test_vi= test_dataset[\"tgt_text\"]\n",
    "\n",
    "print(f\"\\nTest set size: {len(test_vi)} examples\")\n",
    "print(\"\\nTranslating test set...\")\n",
    "\n",
    "# Translate\n",
    "print(\"\\nTranslating test set...\")\n",
    "predictions = translate_batch(test_khm, model, tokenizer)\n",
    "\n",
    "from sacrebleu import corpus_bleu\n",
    "\n",
    "\n",
    "# Calculate BLEU\n",
    "bleu_score = corpus_bleu(predictions, [test_vi])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3076473f-036c-411c-98b5-330f0500188b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE 4 RESULTS (FINAL)\n",
      "======================================================================\n",
      "BLEU Score: 52.34\n",
      "======================================================================\n",
      "\n",
      "Predictions saved to /work/phase4_full/test_predictions.txt\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 14: Final Results\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PHASE 4 RESULTS (FINAL)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"BLEU Score: {bleu_score.score:.2f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save predictions\n",
    "with open(\"./km_to_vi/phase4/test_predictions.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(predictions))\n",
    "\n",
    "print(f\"\\nPredictions saved !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb02a20-e19e-4cee-9ad9-2d65e22db212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SAMPLE TRANSLATIONS\n",
      "======================================================================\n",
      "\n",
      "Example 1:\n",
      "Source    : ▁ទោះជាយ៉ាងណា ក៏ដោយ ▁ ក្នុងអំឡុងពេល ប្រតិបត្តិការ របស់ក្រុមហ៊ុន ▁T i C o ▁លោក ▁Th u an ▁គឺជា អ្នក ទទួលបន្ទុក ដោយផ្ទាល់ លើ ប្រតិបត្តិការ ទាំងអស់ ▁និង ទទួលខុសត្រូវ ទាំងស្រុង ។\n",
      "Reference : Tuy_nhiên , trong quá_trình Công_ty TiCo hoạt_động , Thuận là người trực_tiếp điều_hành mọi công_việc và chịu trách_nhiệm .\n",
      "Prediction: Tuy_nhiên , trong quá_trình hoạt_động của Tập_đoàn TiCo , ông Thuận là người trực_tiếp phụ_trách mọi hoạt_động và hoàn_toàn chịu trách_nhiệm .\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "Source    : ▁ ថ្នាំ ▁M e th ad on e ▁ ជួយ បន្ថយ រោគសញ្ញា នៃការ ដក ថ្នាំ ▁ដោយ កាត់បន្ថយ ការ ឃ្លា ន ▁ការ ប្រកួតប្រជែង ▁និង ផលប៉ះពាល់ នៃ ថ្នាំ ហេ រ៉ូ អ៊ីន យ៉ាងច្រើន ।\n",
      "Reference : Methadone có tác_dụng làm mất các biểu_hiện của hội_chứng_cai , giảm đáng_kể thèm nhớ , cạnh_tranh và khóa tác_động của heroin .\n",
      "Prediction: Methadone giúp làm dịu các triệu_chứng của việc loại_bỏ thuốc bằng cách giảm đáng_kể cơn đói , sự cạnh_tranh và tác_dụng phụ của heroin .\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "Source    : ▁ ទ ួ រ ប៊ី ន ចំនួន ប្រាំ មួយ មកពី ក្រុមហ៊ុន ឧស្សាហកម្ម អាល្លឺម៉ង់ ▁S i e m en s ▁ត្រូវបាន នាំយក មក ទីក្រុង ម៉ុង រ៉េ អាល់ សម្រាប់ការ ថែទាំ ▁នៅពេលដែល ប្រទេស កាណាដា បានប្រកាស ពី ទ ណ្ឌ កម្ម ប្រឆាំងនឹង ប្រទេស រុស្ស៊ី ដោយសារតែ ជម្លោះ នៅ អ៊ុ យ ក្រ ែន ।\n",
      "Reference : Có 6 tuabin của Tập_đoàn công_nghiệp Đức_Siemens đã được đưa đến Montreal để bảo_trì khi Canada tuyên_bố cấm_vận Nga do xung_đột ở Ukraine .\n",
      "Prediction: Sáu tuabin của công_ty công_nghiệp Siemens của Đức được đưa đến Montreal để bảo_trì khi Canada công_bố các lệnh trừng_phạt Nga do xung_đột ở Ukraine .\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 4:\n",
      "Source    : ▁ ថ្មីៗនេះ ▁ ខោ <0xE2> <0x80> <0x8B> ដែល <0xE2> <0x80> <0x8B> មាន <0xE2> <0x80> <0x8B> រាង <0xE2> <0x80> <0x8B> ប៉ ោង <0xE2> <0x80> <0x8B> បាន <0xE2> <0x80> <0x8B> ចាប់ផ្តើម <0xE2> <0x80> <0x8B> វិល <0xE2> <0x80> <0x8B> មក <0xE2> <0x80> <0x8B> រក <0xE2> <0x80> <0x8B> ភាព <0xE2> <0x80> <0x8B> ពេញ <0xE2> <0x80> <0x8B> និយម <0xE2> <0x80> <0x8B> វិញ ▁ហើយ <0xE2> <0x80> <0x8B> កាន់តែ <0xE2> <0x80> <0x8B> មាន <0xE2> <0x80> <0x8B> ប្រជាប្រិយ ភាព <0xE2> <0x80> <0x8B> នៅ <0xE2> <0x80> <0x8B> ក្នុង <0xE2> <0x80> <0x8B> ពិភព <0xE2> <0x80> <0x8B> ម៉ូ ដ ।\n",
      "Reference : Thời_gian gần đây , quần ông loe bắt_đầu quay trở_lại và trở_nên phổ_biến hơn trong giới thời_trang .\n",
      "Prediction: Thời_gian gần đây , quần ống_xả đã bắt_đầu trở_lại trạng_thái_cực_kỳ_vị_thế và trở_nên nổi_bật hơn .\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 5:\n",
      "Source    : ▁បន្ទាប់ពី ការប្រកួត ស្មើ ▁ ០ - ០ ▁ ជាមួយ ក្រុម ▁ U 2 3 ▁ ហ្វីលីពីន ▁អ្នក យុទ្ធសាស្ត្រ កូរ៉េខាងត្បូង បានដាក់ ការ សង្កត់ធ្ងន់ ជាពិសេស ទៅលើ សមត្ថភាព ស៊ុ ត បញ្ចូល ទី របស់ ខ្សែ ប្រយុទ្ធ ।\n",
      "Reference : Sau trận hòa 0 - 0 với U23_Philippines , chiến_lược gia người Hàn_Quốc đặc_biệt chú_trọng đến khả_năng ghi_bàn của các tiền_đạo .\n",
      "Prediction: Sau trận hòa không bàn thắng trước U23_Philippines , chiến_lược gia người Hàn_Quốc đặc_biệt chú_trọng đến khả_năng ghi_bàn của các tiền_đạo .\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 6:\n",
      "Source    : ▁ តម្រូវការ ជា មុន មួយ សម្រាប់ គម្រោង ស មាស ភាគ ទាំង បួន នៃ ផ្លូវ ល្បឿនលឿន ជើង - ត្បូង ▁( ផ្នែក ខាងកើត ) ▁ ដែលត្រូវ បញ្ចប់ នៅចុង ឆ្នាំ ▁２０２２ ▁គឺ ការ ជំនួស ផ្ទះ យ៉ាង ឆាប់ រហ័ស ។\n",
      "Reference : Một trong những yếu_tố tiên_quyết để 4 dự_án thành_phần cao_tốc Bắc - Nam phía Đông_kịp hoàn_thành vào cuối năm 2022 là phải thay_thế nhanh các nhà .\n",
      "Prediction: Một trong những điều_kiện tiên_quyết để 4 dự_án thành_phần cao_tốc Bắc - Nam phía Đông hoàn_thành vào cuối năm 2022 là nhanh_chóng thay_thế nhà ở .\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 7:\n",
      "Source    : ▁ អ្នកស្រាវជ្រាវ បានរកឃើញ ថា ▁ការ ទុក កង ្ ហា រ ឱ្យ បើក យូរ ពេក អាច នាំឱ្យ មានការ ខ្ សោះ ជាតិ ទឹក ▁ មាត់ ▁និង ច្រមុះ ស្ងួត ▁ដោយសារតែ ញ ើ ស ▁និង សំណើ ម ហួត ចេញពី រាងកាយ ។\n",
      "Reference : Các nhà nghiên_cứu đã phát_hiện ra rằng việc bật quạt quá lâu có_thể dẫn đến mất nước và làm khô miệng , mũi do mồ_hôi và hơi ẩm bốc_hơi từ cơ_thể .\n",
      "Prediction: Các nhà nghiên_cứu phát_hiện ra rằng để quạt mở quá lâu có_thể dẫn đến mất nước_bọt và khô mũi do mồ_hôi và độ_ẩm bốc ra khỏi cơ_thể .\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 8:\n",
      "Source    : ▁ការ សម្រេចចិត្ត របស់ វៀតណាម ក្នុងការ នាំ ការប្រកួត ត្រឡប់ទៅ រក លទ្ធផល ស្មើ វិញ បាន ធ្វើឱ្យ ការប្រកួត កាន់តែ គួរឱ្យ រំភើប ▁និង តា ន តឹង នៅ នាទី បន្ត បន្ទាប់ ។\n",
      "Reference : Việc đưa trận_đấu trở về vạch xuất_phát của tuyển Việt_Nam đã giúp cho trận_đấu càng trở_nên hấp_dẫn và quyết_liệt hơn ở những phút sau đó .\n",
      "Prediction: Việc Việt_Nam đưa trận_đấu trở_lại với tỷ_số hòa khiến trận_đấu trở_nên hấp_dẫn và căng_thẳng hơn trong những phút tiếp_theo .\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 9:\n",
      "Source    : ▁សូម ឱ្យ យើង អម ដំណើរ អ្នក ក្នុង ដំណើរ កម្សាន្ត ហា យ៉ាង ដែល មានតម្លៃ សមរម្យ របស់អ្នក ពី ទីក្រុង ហូជីមិញ ▁ហើយ ជួយ អ្នក ឱ្យ ទទួលបាន បទពិសោធន៍ ដ៏អស្ចារ្យ !\n",
      "Reference : Hãy để chúng_tôi đồng_hành cùng bạn trong hành_trình tour du_lịch Hà_Giang từ TP HCM giá tốt và thu về những trải nghiệm tuyệt_vời nhé !\n",
      "Prediction: Hãy cùng chúng_tôi đi cùng bạn trong chuyến du_lịch Hà_Giang giá rẻ từ TPHCM và giúp bạn có những trải nghiệm tuyệt_vời nhé !\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 10:\n",
      "Source    : ▁ ថ្មីៗนี้ ▁ រដ្ឋbàn Biden ▁đã cố_gắng gây áp_lực để Hà_Lan tìm cách ngăn_cản ASML , nhà sản_xuất chip lớn nhất thế_giới , cắt_giảm hợp_tác với các công_ty Trung_Quốc .\n",
      "Reference : Gần đây , chính_quyền Biden tìm cách gây áp_lực với Hà_Lan , yêu_cầu tìm cách can_ngăn ASML , nhà cung_cấp sản_xuất chip lớn nhất thế_giới , giảm bớt sự hợp_tác với các doanh_nghiệp Trung_Quốc .\n",
      "Prediction: Chính_quyền Tổng_thống Biden gần đây đã cố_gắng gây áp_lực để Hà_Lan tìm cách ngăn_cản ASML , nhà sản_xuất chip lớn nhất thế_giới , cắt_giảm hợp_tác với các công_ty Trung_Quốc .\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 15: Sample Translations\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE TRANSLATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Source    : {test_khm[i]}\")\n",
    "    print(f\"Reference : {test_vi[i]}\")\n",
    "    print(f\"Prediction: {predictions[i]}\")\n",
    "    print(\"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "118792a2-48fa-44cf-a51e-fabcae930b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LOADING RESULTS FROM ALL PHASES\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 16: Load All Phase Results\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LOADING RESULTS FROM ALL PHASES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = {\n",
    "    \"phase1\": 18.54,\n",
    "    \"phase2\": 19.67,\n",
    "    \"phase3\": 22.47,\n",
    "    \"phase4\": bleu_score.score\n",
    "}\n",
    "\n",
    "# Try to load previous results\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"./km_to_vi/phase2/phase2_predictions.txt\"):\n",
    "    with open(\"./km_to_vi/phase2/phase2_predictions.txt\", encoding=\"utf-8\") as f:\n",
    "        phase2_preds = [l.strip() for l in f]\n",
    "    results[\"phase2\"] = corpus_bleu(phase2_preds, [test_khm]).score\n",
    "\n",
    "if os.path.exists(\"./km_to_vi/phase3/phase3_predictions.tx\"):\n",
    "    with open(\"./km_to_vi/phase3/phase3_predictions.tx\", encoding=\"utf-8\") as f:\n",
    "        phase3_preds = [l.strip() for l in f]\n",
    "    results[\"phase3\"] = corpus_bleu(phase3_preds, [test_lo]).score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb585d-a3dd-4746-baf9-46690474a6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FINAL RESULTS COMPARISON\n",
      "======================================================================\n",
      "Phase1 (no freeze)       : 45.42 BLEU\n",
      "Phase 2 (decoder only)     : 46.74 BLEU\n",
      "Phase 3 (progressive)      : 50.48 BLEU\n",
      "Phase 4 (full fine-tuning) : 52.34 BLEU\n",
      "\n",
      "Total improvement: +6.92 BLEU\n",
      "======================================================================\n",
      "\n",
      "All results saved!!\n",
      "\n",
      "✓ All 4 phases completed successfully!\n",
      "\n",
      "======================================================================\n",
      "TRAINING PIPELINE FINISHED\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 17: Final Comparison\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Phase1 (no freeze)       : {results['phase1']:.2f} BLEU\")\n",
    "if results['phase2']:\n",
    "    print(f\"Phase 2 (decoder only)     : {results['phase2']:.2f} BLEU\")\n",
    "if results['phase3']:\n",
    "    print(f\"Phase 3 (progressive)      : {results['phase3']:.2f} BLEU\")\n",
    "print(f\"Phase 4 (full fine-tuning) : {results['phase4']:.2f} BLEU\")\n",
    "\n",
    "if results['phase2']:\n",
    "    improvement = results['phase4'] - results['phase1']\n",
    "    print(f\"\\nTotal improvement: +{improvement:.2f} BLEU\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save results\n",
    "with open(\"./km_to_vi/phase4/all_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\nAll results saved!!\")\n",
    "\n",
    "print(\"\\n✓ All 4 phases completed successfully!\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING PIPELINE FINISHED\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adfb5e4-f45d-434d-a6fb-86a85b03c6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ed5022-2cdf-497c-918d-7d92698ed740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988b93da-5783-482b-b834-a430e896877b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
