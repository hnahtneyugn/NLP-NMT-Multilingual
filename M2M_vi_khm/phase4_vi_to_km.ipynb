{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd13816-7db1-40ee-8419-b5e227f76b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.10/site-packages (4.57.3)\n",
      "Requirement already satisfied: sentencepiece in ./.local/lib/python3.10/site-packages (0.2.1)\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.10/site-packages (4.4.2)\n",
      "Requirement already satisfied: sacrebleu in ./.local/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: accelerate in ./.local/lib/python3.10/site-packages (1.12.0)\n",
      "Requirement already satisfied: pyvi in ./.local/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from torch) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.local/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.local/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.local/lib/python3.10/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.local/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.local/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.local/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.local/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.local/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.local/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.local/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.local/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.local/lib/python3.10/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.local/lib/python3.10/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.local/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.local/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.local/lib/python3.10/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.local/lib/python3.10/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.10/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.local/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.10/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in ./.local/lib/python3.10/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in ./.local/lib/python3.10/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.10/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.10/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in ./.local/lib/python3.10/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: portalocker in ./.local/lib/python3.10/site-packages (from sacrebleu) (3.2.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in ./.local/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in ./.local/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in ./.local/lib/python3.10/site-packages (from sacrebleu) (6.0.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: scikit-learn in ./.local/lib/python3.10/site-packages (from pyvi) (1.7.2)\n",
      "Requirement already satisfied: sklearn-crfsuite in ./.local/lib/python3.10/site-packages (from pyvi) (0.5.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.local/lib/python3.10/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.local/lib/python3.10/site-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.local/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.local/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.local/lib/python3.10/site-packages (from scikit-learn->pyvi) (3.6.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.7 in ./.local/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers sentencepiece datasets sacrebleu accelerate pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5761b115-1554-4d7d-b1a4-cd662dd46def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA H200\n",
      "VRAM: 150.0217344 GB\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Setup and imports\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from transformers import (\n",
    "    M2M100ForConditionalGeneration,\n",
    "    M2M100Tokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoTokenizer\n",
    ")\n",
    "import random\n",
    "\n",
    "from pyvi import ViTokenizer\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(\"VRAM:\", torch.cuda.get_device_properties(0).total_memory / 1e9, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5ecb800-5be8-4f26-93f5-fbbbe6cd16b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Khmer tokenizer loaded successfully!\n",
      "Vietnamese and Khmer tokenizers loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Khmer tokenizer\n",
    "# Load Khmer tokenizer from Hugging Face\n",
    "khmer_word_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"khopilot/km-tokenizer-khmer\", \n",
    "    use_fast=False\n",
    ")\n",
    "print(\"Khmer tokenizer loaded successfully!\")\n",
    "\n",
    "# Cell 3b: Define tokenization functions\n",
    "def tokenize_vietnamese(text):\n",
    "    \"\"\"Tokenize Vietnamese text using PyVi\"\"\"\n",
    "    try:\n",
    "        return ViTokenizer.tokenize(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error tokenizing Vietnamese: {e}\")\n",
    "        return text\n",
    "\n",
    "def tokenize_khmer(text):\n",
    "    \"\"\"Tokenize Khmer text using khopilot/km-tokenizer-khmer\"\"\"\n",
    "    try:\n",
    "        tokens = khmer_word_tokenizer.tokenize(text)\n",
    "        return \" \".join(tokens)\n",
    "    except Exception as e:\n",
    "        print(f\"Error tokenizing Khmer: {e}\")\n",
    "        return text\n",
    "\n",
    "def tokenize_batch_vietnamese(texts):\n",
    "    \"\"\"Batch tokenize Vietnamese texts\"\"\"\n",
    "    print(f\"Tokenizing {len(texts)} Vietnamese texts...\")\n",
    "    results = []\n",
    "    for i, text in enumerate(texts):\n",
    "        results.append(tokenize_vietnamese(text))\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print(f\"  Processed {i + 1}/{len(texts)} Vietnamese texts\")\n",
    "    return results\n",
    "\n",
    "def tokenize_batch_khmer(texts):\n",
    "    \"\"\"Batch tokenize Khmer texts\"\"\"\n",
    "    print(f\"Tokenizing {len(texts)} Khmer texts...\")\n",
    "    results = []\n",
    "    for i, text in enumerate(texts):\n",
    "        results.append(tokenize_khmer(text))\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print(f\"  Processed {i + 1}/{len(texts)} Khmer texts\")\n",
    "    return results\n",
    "\n",
    "print(\"Vietnamese and Khmer tokenizers loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24993ec2-666f-4771-b95e-ddd4a994ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = \"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aae468b-46e4-4cfc-b110-bfddfd59055b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Phase 3 model...\n",
      "Model parameters: 483.9M\n",
      "Phase 3 model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 3: Load Phase 3 Model\n",
    "# ============================================================\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "\n",
    "print(\"Loading Phase 3 model...\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./vi_to_km/phase3/best\").cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./vi_to_km/phase3/best\")\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.1f}M\")\n",
    "print(\"Phase 3 model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1d0785-e3e9-4d60-948f-5f049f55df05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unfreezing all parameters...\n",
      "\n",
      "======================================================================\n",
      "PARAMETER STATISTICS\n",
      "======================================================================\n",
      "Total params        : 483.9M\n",
      "Trainable params    : 483.9M\n",
      "  - Encoder         : 201.6M\n",
      "  - Decoder         : 151.2M\n",
      "Trainable %         : 100.0%\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 4: Unfreeze ALL Parameters\n",
    "# ============================================================\n",
    "print(\"\\nUnfreezing all parameters...\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Verify\n",
    "total, trainable = 0, 0\n",
    "encoder_trainable, decoder_trainable = 0, 0\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    n = param.numel()\n",
    "    total += n\n",
    "    \n",
    "    if param.requires_grad:\n",
    "        trainable += n\n",
    "        if \"encoder\" in name:\n",
    "            encoder_trainable += n\n",
    "        elif \"decoder\" in name:\n",
    "            decoder_trainable += n\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PARAMETER STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total params        : {total/1e6:.1f}M\")\n",
    "print(f\"Trainable params    : {trainable/1e6:.1f}M\")\n",
    "print(f\"  - Encoder         : {encoder_trainable/1e6:.1f}M\")\n",
    "print(f\"  - Decoder         : {decoder_trainable/1e6:.1f}M\")\n",
    "print(f\"Trainable %         : 100.0%\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fac730b-90c3-49cd-a487-fecb9908bbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing Vietnamese texts...\n",
      "Tokenizing 599999 Vietnamese texts...\n",
      "  Processed 10000/599999 Vietnamese texts\n",
      "  Processed 20000/599999 Vietnamese texts\n",
      "  Processed 30000/599999 Vietnamese texts\n",
      "  Processed 40000/599999 Vietnamese texts\n",
      "  Processed 50000/599999 Vietnamese texts\n",
      "  Processed 60000/599999 Vietnamese texts\n",
      "  Processed 70000/599999 Vietnamese texts\n",
      "  Processed 80000/599999 Vietnamese texts\n",
      "  Processed 90000/599999 Vietnamese texts\n",
      "  Processed 100000/599999 Vietnamese texts\n",
      "  Processed 110000/599999 Vietnamese texts\n",
      "  Processed 120000/599999 Vietnamese texts\n",
      "  Processed 130000/599999 Vietnamese texts\n",
      "  Processed 140000/599999 Vietnamese texts\n",
      "  Processed 150000/599999 Vietnamese texts\n",
      "  Processed 160000/599999 Vietnamese texts\n",
      "  Processed 170000/599999 Vietnamese texts\n",
      "  Processed 180000/599999 Vietnamese texts\n",
      "  Processed 190000/599999 Vietnamese texts\n",
      "  Processed 200000/599999 Vietnamese texts\n",
      "  Processed 210000/599999 Vietnamese texts\n",
      "  Processed 220000/599999 Vietnamese texts\n",
      "  Processed 230000/599999 Vietnamese texts\n",
      "  Processed 240000/599999 Vietnamese texts\n",
      "  Processed 250000/599999 Vietnamese texts\n",
      "  Processed 260000/599999 Vietnamese texts\n",
      "  Processed 270000/599999 Vietnamese texts\n",
      "  Processed 280000/599999 Vietnamese texts\n",
      "  Processed 290000/599999 Vietnamese texts\n",
      "  Processed 300000/599999 Vietnamese texts\n",
      "  Processed 310000/599999 Vietnamese texts\n",
      "  Processed 320000/599999 Vietnamese texts\n",
      "  Processed 330000/599999 Vietnamese texts\n",
      "  Processed 340000/599999 Vietnamese texts\n",
      "  Processed 350000/599999 Vietnamese texts\n",
      "  Processed 360000/599999 Vietnamese texts\n",
      "  Processed 370000/599999 Vietnamese texts\n",
      "  Processed 380000/599999 Vietnamese texts\n",
      "  Processed 390000/599999 Vietnamese texts\n",
      "  Processed 400000/599999 Vietnamese texts\n",
      "  Processed 410000/599999 Vietnamese texts\n",
      "  Processed 420000/599999 Vietnamese texts\n",
      "  Processed 430000/599999 Vietnamese texts\n",
      "  Processed 440000/599999 Vietnamese texts\n",
      "  Processed 450000/599999 Vietnamese texts\n",
      "  Processed 460000/599999 Vietnamese texts\n",
      "  Processed 470000/599999 Vietnamese texts\n",
      "  Processed 480000/599999 Vietnamese texts\n",
      "  Processed 490000/599999 Vietnamese texts\n",
      "  Processed 500000/599999 Vietnamese texts\n",
      "  Processed 510000/599999 Vietnamese texts\n",
      "  Processed 520000/599999 Vietnamese texts\n",
      "  Processed 530000/599999 Vietnamese texts\n",
      "  Processed 540000/599999 Vietnamese texts\n",
      "  Processed 550000/599999 Vietnamese texts\n",
      "  Processed 560000/599999 Vietnamese texts\n",
      "  Processed 570000/599999 Vietnamese texts\n",
      "  Processed 580000/599999 Vietnamese texts\n",
      "  Processed 590000/599999 Vietnamese texts\n",
      "Tokenizing Khmer texts...\n",
      "Tokenizing 599999 Khmer texts...\n",
      "  Processed 10000/599999 Khmer texts\n",
      "  Processed 20000/599999 Khmer texts\n",
      "  Processed 30000/599999 Khmer texts\n",
      "  Processed 40000/599999 Khmer texts\n",
      "  Processed 50000/599999 Khmer texts\n",
      "  Processed 60000/599999 Khmer texts\n",
      "  Processed 70000/599999 Khmer texts\n",
      "  Processed 80000/599999 Khmer texts\n",
      "  Processed 90000/599999 Khmer texts\n",
      "  Processed 100000/599999 Khmer texts\n",
      "  Processed 110000/599999 Khmer texts\n",
      "  Processed 120000/599999 Khmer texts\n",
      "  Processed 130000/599999 Khmer texts\n",
      "  Processed 140000/599999 Khmer texts\n",
      "  Processed 150000/599999 Khmer texts\n",
      "  Processed 160000/599999 Khmer texts\n",
      "  Processed 170000/599999 Khmer texts\n",
      "  Processed 180000/599999 Khmer texts\n",
      "  Processed 190000/599999 Khmer texts\n",
      "  Processed 200000/599999 Khmer texts\n",
      "  Processed 210000/599999 Khmer texts\n",
      "  Processed 220000/599999 Khmer texts\n",
      "  Processed 230000/599999 Khmer texts\n",
      "  Processed 240000/599999 Khmer texts\n",
      "  Processed 250000/599999 Khmer texts\n",
      "  Processed 260000/599999 Khmer texts\n",
      "  Processed 270000/599999 Khmer texts\n",
      "  Processed 280000/599999 Khmer texts\n",
      "  Processed 290000/599999 Khmer texts\n",
      "  Processed 300000/599999 Khmer texts\n",
      "  Processed 310000/599999 Khmer texts\n",
      "  Processed 320000/599999 Khmer texts\n",
      "  Processed 330000/599999 Khmer texts\n",
      "  Processed 340000/599999 Khmer texts\n",
      "  Processed 350000/599999 Khmer texts\n",
      "  Processed 360000/599999 Khmer texts\n",
      "  Processed 370000/599999 Khmer texts\n",
      "  Processed 380000/599999 Khmer texts\n",
      "  Processed 390000/599999 Khmer texts\n",
      "  Processed 400000/599999 Khmer texts\n",
      "  Processed 410000/599999 Khmer texts\n",
      "  Processed 420000/599999 Khmer texts\n",
      "  Processed 430000/599999 Khmer texts\n",
      "  Processed 440000/599999 Khmer texts\n",
      "  Processed 450000/599999 Khmer texts\n",
      "  Processed 460000/599999 Khmer texts\n",
      "  Processed 470000/599999 Khmer texts\n",
      "  Processed 480000/599999 Khmer texts\n",
      "  Processed 490000/599999 Khmer texts\n",
      "  Processed 500000/599999 Khmer texts\n",
      "  Processed 510000/599999 Khmer texts\n",
      "  Processed 520000/599999 Khmer texts\n",
      "  Processed 530000/599999 Khmer texts\n",
      "  Processed 540000/599999 Khmer texts\n",
      "  Processed 550000/599999 Khmer texts\n",
      "  Processed 560000/599999 Khmer texts\n",
      "  Processed 570000/599999 Khmer texts\n",
      "  Processed 580000/599999 Khmer texts\n",
      "  Processed 590000/599999 Khmer texts\n",
      "Total dataset size: 599999 examples\n",
      "Train dataset: 595999 examples (for training)\n",
      "Dev dataset  : 3000 examples (for validation during training)\n",
      "Test dataset : 1000 examples (for final evaluation)\n",
      "\n",
      "Data split and shuffle completed.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Load and prepare data\n",
    "\n",
    "def load_parallel(src_file, tgt_file):\n",
    "    with open(src_file, encoding=\"utf-8\") as f:\n",
    "        src = [l.strip() for l in f]\n",
    "    with open(tgt_file, encoding=\"utf-8\") as f:\n",
    "        tgt = [l.strip() for l in f]\n",
    "    \n",
    "    assert len(src) == len(tgt)\n",
    "\n",
    "    print(\"Tokenizing Vietnamese texts...\")\n",
    "    src_tokenized = tokenize_batch_vietnamese(src)\n",
    "    \n",
    "    print(\"Tokenizing Khmer texts...\")\n",
    "    tgt_tokenized = tokenize_batch_khmer(tgt) \n",
    "    \n",
    "    return Dataset.from_dict({\n",
    "        \"src_text\": src_tokenized,\n",
    "        \"tgt_text\": tgt_tokenized\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "# Load data from train.khm and train.vi\n",
    "full_dataset = load_parallel(\n",
    "    f\"{DATA_DIR}/train_khm.vi\",\n",
    "    f\"{DATA_DIR}/train_khm.khm\"\n",
    ")\n",
    "\n",
    "print(f\"Total dataset size: {len(full_dataset)} examples\")\n",
    "\n",
    "# Split dataset\n",
    "test_size = 1000\n",
    "dev_size = 3000\n",
    "\n",
    "test_start_idx = len(full_dataset) - test_size\n",
    "dev_start_idx = test_start_idx - dev_size\n",
    "\n",
    "test_dataset = full_dataset.select(range(test_start_idx, len(full_dataset)))\n",
    "dev_dataset = full_dataset.select(range(dev_start_idx, test_start_idx))\n",
    "train_dataset = full_dataset.select(range(0, dev_start_idx))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(seed=42)\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)} examples (for training)\")\n",
    "print(f\"Dev dataset  : {len(dev_dataset)} examples (for validation during training)\")\n",
    "print(f\"Test dataset : {len(test_dataset)} examples (for final evaluation)\")\n",
    "print(\"\\nData split and shuffle completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3b9e1f5-176a-4bf2-9a84-8d674eb347f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Preprocessing function\n",
    "MAX_LEN = 256\n",
    "\n",
    "def preprocess(batch):\n",
    "    tokenizer.src_lang = \"vi\"  # Changed from \"lo\" to \"km\" for Khmer\n",
    "    tokenizer.tgt_lang = \"km\"\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        batch[\"src_text\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            batch[\"tgt_text\"],\n",
    "            truncation=True,\n",
    "            max_length=MAX_LEN\n",
    "        )\n",
    "\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59e725b7-9ac7-49d7-ba82-9905c6bbbf74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee9db6d1d5549ecb55defdd0af803e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/595999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164e5a15fe6849a5b85e7a726d26f9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/admin/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Apply preprocessing\n",
    "train_dataset = train_dataset.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    num_proc=8\n",
    ")\n",
    "\n",
    "dev_dataset = dev_dataset.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=dev_dataset.column_names,\n",
    "    num_proc=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c36f3c1-792e-4ece-8268-07135281cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: Data Collator\n",
    "# ============================================================\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa1778f3-41e6-4c07-a1dc-d6913f31271f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training configuration:\n",
      "Effective batch size: 512\n",
      "Learning rate: 5e-05\n",
      "Epochs: 12\n",
      "Label smoothing: 0.15\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 8: Training Arguments\n",
    "# ============================================================\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./vi_to_km/phase4\",\n",
    "    \n",
    "    # Evaluation & Saving\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    \n",
    "    # Logging\n",
    "    logging_steps=100,    \n",
    "    # Batch size\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=4,\n",
    "    \n",
    "    # Learning rate - VERY LOW for full fine-tuning\n",
    "    learning_rate=5e-5 ,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_ratio=0.08,\n",
    "    \n",
    "    # Regularization - STRONGER to prevent overfitting\n",
    "    weight_decay=0.1,\n",
    "    max_grad_norm=0.4,  # Stricter clipping\n",
    "    \n",
    "    # Training\n",
    "    num_train_epochs=12,\n",
    "    \n",
    "    # FP16\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "\n",
    "    # Speed\n",
    "    group_by_length=True,\n",
    "    dataloader_num_workers=8,\n",
    "    dataloader_pin_memory=True,\n",
    "    \n",
    "    \n",
    "    # Best model\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    \n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "print(\"\\nTraining configuration:\")\n",
    "print(f\"Effective batch size: {128 * 4}\")\n",
    "print(f\"Learning rate: {5e-5 }\")\n",
    "print(f\"Epochs: {12}\")\n",
    "print(f\"Label smoothing: 0.15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c17a20a3-e687-4abf-9ad2-37814d4b0c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6843/2995964508.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 9: Create Trainer\n",
    "# ============================================================\n",
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=dev_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[\n",
    "            EarlyStoppingCallback(early_stopping_patience=6)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36148642-bead-49ae-8ad6-2e8ee3d0b763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STARTING PHASE 4: FULL FINE-TUNING\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13980' max='13980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13980/13980 2:00:53, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.679800</td>\n",
       "      <td>0.694644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.702900</td>\n",
       "      <td>0.698146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.688400</td>\n",
       "      <td>0.691658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.684700</td>\n",
       "      <td>0.684160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.656400</td>\n",
       "      <td>0.677242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.657600</td>\n",
       "      <td>0.671043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.651900</td>\n",
       "      <td>0.667021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.629400</td>\n",
       "      <td>0.666786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.633500</td>\n",
       "      <td>0.663253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.607900</td>\n",
       "      <td>0.661816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.608100</td>\n",
       "      <td>0.655212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.580700</td>\n",
       "      <td>0.654980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.588900</td>\n",
       "      <td>0.649732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.587100</td>\n",
       "      <td>0.652200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.568500</td>\n",
       "      <td>0.653324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.572500</td>\n",
       "      <td>0.647342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.554300</td>\n",
       "      <td>0.648690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.554700</td>\n",
       "      <td>0.646116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.537000</td>\n",
       "      <td>0.646083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.544700</td>\n",
       "      <td>0.644899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.538800</td>\n",
       "      <td>0.642667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.529200</td>\n",
       "      <td>0.642511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.529600</td>\n",
       "      <td>0.643792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.518900</td>\n",
       "      <td>0.644911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.517300</td>\n",
       "      <td>0.642694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.511200</td>\n",
       "      <td>0.642862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.510500</td>\n",
       "      <td>0.641664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING COMPLETED\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 10: Train\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING PHASE 4: FULL FINE-TUNING\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "609fc963-edba-46d5-b652-0cb976048f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving best model...\n",
      "Model saved!!! \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 11: Save Model\n",
    "# ============================================================\n",
    "print(\"\\nSaving best model...\")\n",
    "trainer.save_model(\"./vi_to_km/phase4/best\")\n",
    "tokenizer.save_pretrained(\"./vi_to_km/phase4/best\")\n",
    "print(f\"Model saved!!! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95504577-5450-41ea-a473-c27d069a922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 12: Evaluation Function\n",
    "# ============================================================\n",
    "def translate_batch(texts, model, tokenizer, batch_size=32):\n",
    "    \"\"\"Batch translation for speed\"\"\"\n",
    "    model.eval()\n",
    "    tokenizer.src_lang = \"vi\"\n",
    "    tokenizer.tgt_lang = \"km\"\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        \n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=256\n",
    "        ).to(\"cuda\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            gen = model.generate(\n",
    "                **inputs,\n",
    "                forced_bos_token_id=tokenizer.get_lang_id(\"km\"),\n",
    "                num_beams=5,\n",
    "                max_length=256\n",
    "            )\n",
    "        \n",
    "        texts_out = tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
    "        outputs.extend(texts_out)\n",
    "        \n",
    "        if (i // batch_size + 1) % 10 == 0:\n",
    "            print(f\"Translated {i+len(batch)}/{len(texts)}\")\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f30a369c-2dd3-4c39-bd93-2fb8017cdcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set size: 1000 examples\n",
      "\n",
      "Translating test set...\n",
      "\n",
      "Translating test set...\n",
      "Translated 320/1000\n",
      "Translated 640/1000\n",
      "Translated 960/1000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 13: Evaluate on Test Set\n",
    "# ============================================================\n",
    "# Load test data\n",
    "# Lấy dữ liệu test từ test_dataset (đã chia từ train.vi/train.lo)\n",
    "test_vi = test_dataset[\"src_text\"]\n",
    "test_khm = test_dataset[\"tgt_text\"]\n",
    "\n",
    "print(f\"\\nTest set size: {len(test_vi)} examples\")\n",
    "print(\"\\nTranslating test set...\")\n",
    "\n",
    "# Translate\n",
    "print(\"\\nTranslating test set...\")\n",
    "predictions = translate_batch(test_vi, model, tokenizer)\n",
    "\n",
    "from sacrebleu import corpus_bleu\n",
    "\n",
    "\n",
    "# Calculate BLEU\n",
    "bleu_score = corpus_bleu(predictions, [test_khm])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3076473f-036c-411c-98b5-330f0500188b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PHASE 4 RESULTS (FINAL)\n",
      "======================================================================\n",
      "BLEU Score: 23.82\n",
      "======================================================================\n",
      "\n",
      "Predictions saved !!!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 14: Final Results\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PHASE 4 RESULTS (FINAL)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"BLEU Score: {bleu_score.score:.2f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save predictions\n",
    "with open(\"./vi_to_km/phase4/test_predictions.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(predictions))\n",
    "\n",
    "print(f\"\\nPredictions saved !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adb02a20-e19e-4cee-9ad9-2d65e22db212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SAMPLE TRANSLATIONS\n",
      "======================================================================\n",
      "\n",
      "Example 1:\n",
      "Source    : Ủy_ban bầu_cử Myanmar đã bác_bỏ tuyên_bố này .\n",
      "Reference : ▁ គណៈកម្មការ រៀបចំការបោះឆ្នោត របស់ប្រទេស មីយ៉ាន់ម៉ា បាន ច្រ ា ន ចោល ការ អះអាង នេះ ។\n",
      "Prediction: ការ អះអាង នេះត្រូវបាន គណៈកម្មការ រៀបចំការបោះឆ្នោត មីយ៉ាន់ម៉ា ច្រ ា ន ចោល ។\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "Source    : Bộ_trưởng nói : \" Phụ_nữ cũng muốn được lên_tiếng , được nêu lên những vấn_đề của chính mình . Trong quá_khứ , phụ_nữ nhận thấy rằng những người_làm chính_trị không thực_sự nêu lên những vấn_đề của chính họ vì bản_thân họ chưa từng đối_mặt với những vấn_đề đó . \"\n",
      "Reference : ▁លោកស្រី រដ្ឋមន្ត្រី មានប្រសាសន៍ថា ៖ « ស្ត្រី ក៏ ចង់បាន ស្រ្តី ជា សំឡេង ខ្លួន ដែរ ▁ លើក បញ្ហា របស់ ខ្លួនឯង ▁ដែល កន្លងមក ស្ត្រី ឃើញថា ▁ អ្នកដែល ធ្វើ នយោបាយ ▁លោក មិនបាន លើក បញ្ហា ខ្លួន ឲ្យ ពិត ជាក់ស្តែង ▁ដោយសារ លោក មិនបាន ជួប បញ្ហា ហ្នឹង ដោយ ខ្លួន គាត់ ។\n",
      "Prediction: លោកស្រី រដ្ឋមន្រ្តី មានប្រសាសន៍ថា ៖ « ស្ត្រី ក៏ ចង់ឲ្យ មានការ បញ្ចេញមតិ ការ លើកឡើង នូវ បញ្ហា ផ្ទាល់ខ្លួន កន្លងមក ស្ត្រី យល់ ឃើញថា អ្នក ធ្វើ នយោបាយ ហ្នឹង គាត់ អត់ សូ វ លើកឡើង នូវ បញ្ហា ផ្ទាល់ខ្លួន ទេ ព្រោះ ខ្លួន គាត់ អត់ បាន ប្រឈម បញ្ហា ហ្នឹង ទេ ។\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "Source    : Thầy Om Phearum cho biết vì thầy dạy toán nên thầy hướng_dẫn học_sinh_học môn này vào lúc 7 giờ sáng trong khoảng 45 phút , theo một video do một giáo_viên khác quay .\n",
      "Reference : ▁ លោកគ្រូ ▁ អ៊ ុំ ▁ ភា រ ម ្យ បន្តថា ▁ដោយសារ លោក បង្រៀន គណ ិត វិទ្យា ▁ដូច្នេះ លោក ដឹកនាំ សិស្ស រៀន មុខ វិជ្ជា នេះ នៅពេល ព្រឹក ម៉ោង ៧ ▁ ប្រហែលជា ៤៥ នាទី ▁ ទៅតាម វីដេអូ ដែល ថត បង្រៀន ដោយ គ្រូ ផ្សេង ។\n",
      "Prediction: លោកគ្រូ ឱ ម ភា រ ម ្យ បញ្ជាក់ថា ដោយសារ លោកគ្រូ អ្នក គ្រូ គណ ិត វិទ្យា លោកគ្រូ បាន ណែនាំ សិស្ស ឲ្យ រៀន មុខ វិជ្ជា នេះ នៅម៉ោង ៧ ព្រឹក ប្រមាណ ៤៥ នាទី តាម វីដេអូ ដែល ថត ដោយ គ្រូ ម្នាក់ទៀត ។\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 4:\n",
      "Source    : Thủ_tướng Hun_Sen hôm thứ Tư đã gọi tuyên_bố của Sam Rainsy thông_qua video là sự liên_hệ đến video của Kem_Sokha , người đang bị buộc_tội phản_quốc vì tiết_lộ kế_hoạch lật_đổ chính_phủ với sự thông_đồng của Hoa_Kỳ .\n",
      "Reference : ▁លោក នាយករដ្ឋមន្រ្តី ▁ហ៊ុន ▁សែន ▁ កាលពីថ្ងៃពុធ ▁បាន ហៅ ការ ថ្លែង របស់លោក ▁សម ▁រង្ស៊ី ▁តាមរយៈ វីដេអូ នេះ ថា ▁ ជាការ ផ្សារ ភ្ជាប់ ទៅនឹង វីដេអូ របស់ ▁លោក ▁កឹម ▁សុខា ▁ ដែលកំពុង ជាប់ ចោទ ពីបទ ក ្ បត់ ជាតិ ▁ ព្រោះតែ បង្ហាញ គម្រោង ផ្ ត ួល រំ លំ រាជរដ្ឋាភិបាល ▁ដោយ ឃ ុប ឃ ិត ជាមួយ សហរដ្ឋអាមេរិក ។\n",
      "Prediction: លោក នាយករដ្ឋមន្រ្តី ហ៊ុន សែន នៅ ថ្ងៃពុធ នេះ បាន ហៅ ស េចក្តីថ្លែងការណ៍ របស់លោក សម រង្ស៊ី តាមរយៈ វីដេអូ នោះ ថា ជាការ ភ្ជាប់ វីដេអូ របស់លោក កឹម សុខា ដែលត្រូវបាន ចោទប្រកាន់ ថា បាន ប្រព្រឹត្ត អំពើ ក ្ បត់ ជាតិ ដោយសារ លោក បានបង្ហាញ ផែនការ ផ្ ត ួល រំ លំ រដ្ឋាភិបាល ដោយ មានការ ឃ ុប ឃ ិត របស់ សហរដ្ឋអាមេរិក ។\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 5:\n",
      "Source    : Tuần trước , truyền_thông nhà_nước Trung_Quốc đưa tin rằng Bắc_Kinh hy_vọng sẽ hoàn_tất bộ quy_tắc ứng_xử cho Biển Đông vốn bị trì_hoãn từ lâu trong năm 2017 .\n",
      "Reference : ▁ សារព័ត៌មាន រដ្ឋ របស់ ចិន កាលពី សប្តាហ៍ មុន បាន រាយការណ៍ ថា ▁ រដ្ឋាភិបាល ក្រុង ប៉េ ក ាំង សង្ឃឹមថា ▁នឹង សម្រេច ក្រម ប្រតិបត្តិ ដែលត្រូវបាន ពន្ យា រ ពេល យ៉ាង យូរ សម្រាប់ ស មុទ្រចិនខាងត្បូង ▁នៅក្នុង ឆ្នាំ២០១៧ ខាងមុខនេះ ។\n",
      "Prediction: បណ្តាញ ផ្សាយ ព័ត៌មាន រដ្ឋ ចិន បាន រាយការណ៍ កាលពី សប្តាហ៍ មុន ថា រដ្ឋាភិបាល ក្រុង ប៉េ ក ាំង សង្ឃឹមថា នឹង បញ្ចប់ ក្រម ប្រតិបត្តិ សម្រាប់ ស មុទ្រចិនខាងត្បូង ដែលបាន ត្រូវ ពន្ យា រ ពេល ជា យូរ មកហើយ នៅក្នុង ឆ្នាំ២០១៧ ។\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 6:\n",
      "Source    : Trong bối_cảnh Campuchia đang hướng tới cuộc bầu_cử quốc_hội sắp tới , ông Say Chhum cũng đề_cập trong thông_điệp của mình rằng người dân Campuchia sẽ có quyền thành_lập Quốc_hội , từ đó dẫn đến việc bầu ra một chính_phủ mới .\n",
      "Reference : ▁ដោយ ហេតុ ថា ▁ កម្ពុជា ក៏ កំពុង ឆ្ពោះទៅ រក ការបោះឆ្នោត ជ្រើសតាំង តំណាងរាស្ត្រ នៅពេល ខាងមុខនេះ ▁លោក ▁ សាយ ▁ ឈ ុំ ▁ក៏ បានលើកឡើង ក្នុង សារ លិខិត របស់លោក ថា ▁ ប្រជាពលរដ្ឋខ្មែរ ▁ នឹងមាន សិទ្ធិ ក្នុងការ បង្កើត រដ្ឋសភា ដែល នឹង នាំ ដល់ ការ ជ្រើសតាំង រដ្ឋាភិបាល ថ្មីមួយ ។\n",
      "Prediction: ស្រប ពេលដែល កម្ពុជា កំពុង សម្លឹង ឆ្ពោះទៅ រក ការបោះឆ្នោត ជ្រើសតាំង តំណាងរាស្ត្រ នាពេលខាងមុខ លោក សាយ ឈ ុំ ក៏ បានលើកឡើង ក្នុង សារ របស់លោក ថា ពលរដ្ឋ កម្ពុជា នឹងមាន សិទ្ធិ ក្នុងការ បង្កើត រដ្ឋសភា ដែល នឹង ឈានទៅ ដល់ ការ ជ្រើសតាំង រដ្ឋាភិបាល ថ្មីមួយ ។\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 7:\n",
      "Source    : \" Họ nói họ muốn đánh_dấu vào phiếu bầu , nhưng họ không_thể . \"\n",
      "Reference : ▁ ថា ចង់ គូ ស សន្លឹកឆ្នោត ▁មិន ឲ្យបាន ការ » ។\n",
      "Prediction: គេ ថា គេ ចង់ គូ ស សន្លឹកឆ្នោត ចោល តែ គេ មិនអាច គូ ស បាន » ។\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 8:\n",
      "Source    : Đây không phải là lần đầu_tiên bà Sithar bị bắt vì đòi quyền_lợi cho người lao_động .\n",
      "Reference : ▁ នេះ មិនមែនជា លើកទី ▁១ ▁ ទេ ដែល ▁ ស៊ី ថ រ ▁ត្រូវបាន ចាប់ខ្លួន ដោយសារ ការ ទាមទារ សិទ្ធិ ▁និង អត្ថប្រយោជន៍ ឲ្យ បុគ្គលិក ។\n",
      "Prediction: នេះ មិនមែនជា លើកទី មួយ ទេ ដែល កញ្ញា ស៊ី ថ រ ត្រូវបាន ចាប់ខ្លួន ដោយសារតែ ការ ទាមទារ សិទ្ធិ របស់ កម្មករ ។\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 9:\n",
      "Source    : Sự gia_tăng bạo_lực dựa trên giới_tính được gọi là một đại_dịch tiềm_ẩn .\n",
      "Reference : ▁បាន ហៅ ការ កើនឡើង នៃ អំពើហិង្សា ផ្អែក លើ យ៉ ែន ឌ ័រ នេះ ថា ▁ ជាការ រា ត ត ្ បាត ដោយ លាក់ កំ បាំង ។\n",
      "Prediction: ការ កើនឡើង នៃ អំពើហិង្សា យ េន ឌ ័រ ត្រូវបានគេ ស្គាល់ ថា ជា ជំងឺ រា ត ត ្ បាត ដែលអាច កើតមាន ។\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 10:\n",
      "Source    : \" Trưởng lâm_nghiệp đã lấy nó rồi ... việc này không liên_quan gì đến chúng_tôi cả . \"\n",
      "Reference : ▁ មេ ព្រៃ គេ ទៅ យក . ... អត់ មាន ពាក់ព័ន្ធ អី ជាមួយ ពួក ខ្ញុំ ផង » ។\n",
      "Prediction: « ប្រធាន ព្រៃឈើ គេ យក ហើយ ... អត់ មាន ពាក់ព័ន្ធ អី ជាមួយ យើង ទេ ។\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 15: Sample Translations\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE TRANSLATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Source    : {test_vi[i]}\")\n",
    "    print(f\"Reference : {test_khm[i]}\")\n",
    "    print(f\"Prediction: {predictions[i]}\")\n",
    "    print(\"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "118792a2-48fa-44cf-a51e-fabcae930b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LOADING RESULTS FROM ALL PHASES\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 16: Load All Phase Results\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LOADING RESULTS FROM ALL PHASES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = {\n",
    "    \"phase1\": 18.54,\n",
    "    \"phase2\": 19.67,\n",
    "    \"phase3\": 22.47,\n",
    "    \"phase4\": bleu_score.score\n",
    "}\n",
    "\n",
    "# Try to load previous results\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"./vi_to_km/phase2/phase2_predictions.txt\"):\n",
    "    with open(\"./vi_to_km/phase2/phase2_predictions.txt\", encoding=\"utf-8\") as f:\n",
    "        phase2_preds = [l.strip() for l in f]\n",
    "    results[\"phase2\"] = corpus_bleu(phase2_preds, [test_khm]).score\n",
    "\n",
    "if os.path.exists(\"./vi_to_km/phase3/phase3_predictions.tx\"):\n",
    "    with open(\"./vi_to_km/phase3/phase3_predictions.tx\", encoding=\"utf-8\") as f:\n",
    "        phase3_preds = [l.strip() for l in f]\n",
    "    results[\"phase3\"] = corpus_bleu(phase3_preds, [test_lo]).score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8feb585d-a3dd-4746-baf9-46690474a6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL RESULTS COMPARISON\n",
      "======================================================================\n",
      "Phase1 (no freeze)       : 18.54 BLEU\n",
      "Phase 2 (decoder only)     : 19.67 BLEU\n",
      "Phase 3 (progressive)      : 22.47 BLEU\n",
      "Phase 4 (full fine-tuning) : 23.82 BLEU\n",
      "\n",
      "Total improvement: +5.28 BLEU\n",
      "======================================================================\n",
      "\n",
      "All results saved!!\n",
      "\n",
      "✓ All 4 phases completed successfully!\n",
      "\n",
      "======================================================================\n",
      "TRAINING PIPELINE FINISHED\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 17: Final Comparison\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Phase1 (no freeze)       : {results['phase1']:.2f} BLEU\")\n",
    "if results['phase2']:\n",
    "    print(f\"Phase 2 (decoder only)     : {results['phase2']:.2f} BLEU\")\n",
    "if results['phase3']:\n",
    "    print(f\"Phase 3 (progressive)      : {results['phase3']:.2f} BLEU\")\n",
    "print(f\"Phase 4 (full fine-tuning) : {results['phase4']:.2f} BLEU\")\n",
    "\n",
    "if results['phase2']:\n",
    "    improvement = results['phase4'] - results['phase1']\n",
    "    print(f\"\\nTotal improvement: +{improvement:.2f} BLEU\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save results\n",
    "with open(\"./vi_to_km/phase4/all_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\nAll results saved!!\")\n",
    "\n",
    "print(\"\\n✓ All 4 phases completed successfully!\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING PIPELINE FINISHED\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adfb5e4-f45d-434d-a6fb-86a85b03c6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ed5022-2cdf-497c-918d-7d92698ed740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988b93da-5783-482b-b834-a430e896877b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
